{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b812534f",
   "metadata": {},
   "source": [
    "# Knowledge-Aware Recommender with Graph & Text Fusion\n",
    "\n",
    "\n",
    "**Key Improvements over the Paper:**\n",
    "1.  **Relational GAT (RGAT):** Instead of standard CompGCN, we use Attention *plus* Relation Embeddings. This allows the model to learn that for some movies, the \"Director\" edge is more important than the \"Genre\" edge.\n",
    "2.  **Dual-View Text Encoding:** We handle Overviews and Reviews separately using a Hierarchical Attention mechanism.\n",
    "3.  **Contrastive Learning (InfoNCE):** We add an auxiliary loss function that forces the Graph embeddings and Text embeddings of the same item to align in the latent space.\n",
    "\n",
    "**Architecture:**\n",
    "* **Input:** Heterogeneous Graph (DGL) + Text Features (Overviews, Reviews).\n",
    "* **Graph Module:** Relational GAT layers.\n",
    "* **Text Module:** SBERT embeddings -> Attention Aggregation.\n",
    "* **Fusion:** Cross-Attention with Gating.\n",
    "* **Loss:** BPR Loss (Ranking) + InfoNCE Loss (Contrastive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4eb77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.function as fn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import defaultdict\n",
    "from utils.recomender_metrics import evaluate_recommendations, print_evaluation_results\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "EMBED_DIM = 64\n",
    "HIDDEN_DIM = 128\n",
    "ATTENTION_HEADS = 4\n",
    "DROPOUT = 0.3\n",
    "LR = 0.001\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128 # Smaller batch size usually better for contrastive loss\n",
    "TEXT_EMBED_PATH = '../data/processed/movie_text_embeddings.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8d74ab",
   "metadata": {},
   "source": [
    "## 1. Data Preparation\n",
    "We load the processed files and construct a Heterogeneous DGL Graph.\n",
    "Ideally, we would load the `movie_knowledge_graph.graphml` directly, but mapping it to tensors for training is often cleaner when rebuilding from CSVs to ensure integer IDs are contiguous.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8fde46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_and_build_graph():\n",
    "    print(\"Loading datasets...\")\n",
    "    \n",
    "    movies_df = pd.read_csv('../data/processed/movies_graph_ready.csv')\n",
    "    train_df = pd.read_csv('../data/raw/ml-100k/u1.base', sep='\\t', names=['user_id', 'movie_id', 'rating', 'timestamp'])\n",
    "    test_df = pd.read_csv('../data/raw/ml-100k/u1.test', sep='\\t', names=['user_id', 'movie_id', 'rating', 'timestamp'])\n",
    "    \n",
    "    # auxiliary node files\n",
    "    nodes_dir = '../data/processed/nodes'\n",
    "    genres_df = pd.read_csv(f'{nodes_dir}/genres.csv')\n",
    "    keywords_df = pd.read_csv(f'{nodes_dir}/keywords.csv')\n",
    "    directors_df = pd.read_csv(f'{nodes_dir}/directors.csv')\n",
    "    writers_df = pd.read_csv(f'{nodes_dir}/writers.csv')\n",
    "    \n",
    "    # --- ID MAPPING ---\n",
    "    # Combined Users/Items to ensure consistency across Train/Test\n",
    "    all_users = pd.concat([train_df['user_id'], test_df['user_id']]).unique()\n",
    "    all_movies = movies_df['ml_movie_id'].unique()\n",
    "    \n",
    "    user_map = {uid: i for i, uid in enumerate(all_users)}\n",
    "    movie_map = {mid: i for i, mid in enumerate(all_movies)}\n",
    "    \n",
    "    # Reverse maps for final output\n",
    "    id_to_user = {v: k for k, v in user_map.items()}\n",
    "    id_to_movie = {v: k for k, v in movie_map.items()}\n",
    "    \n",
    "    # Aux nodes\n",
    "    genre_map = {gid: i for i, gid in enumerate(genres_df['id'])}\n",
    "    keyword_map = {kid: i for i, kid in enumerate(keywords_df['id'])}\n",
    "    director_map = {did: i for i, did in enumerate(directors_df['id'])}\n",
    "    writer_map = {wid: i for i, wid in enumerate(writers_df['id'])}\n",
    "    \n",
    "    # --- EDGE CONSTRUCTION (Only using Training Data) ---\n",
    "    data_dict = {}\n",
    "    \n",
    "    # User-Movie Edges (Ratings >= 4)\n",
    "    pos_ratings = train_df[train_df['rating'] >= 4]\n",
    "    \n",
    "    u_src = []\n",
    "    m_dst = []\n",
    "    \n",
    "    valid_u = set(user_map.keys())\n",
    "    valid_m = set(movie_map.keys())\n",
    "    \n",
    "    print(\"Building User-Movie edges...\")\n",
    "    for u, m in zip(pos_ratings['user_id'], pos_ratings['movie_id']):\n",
    "        if u in valid_u and m in valid_m:\n",
    "            u_src.append(user_map[u])\n",
    "            m_dst.append(movie_map[m])\n",
    "    \n",
    "    data_dict[('user', 'rates', 'movie')] = (torch.tensor(u_src, dtype=torch.long), torch.tensor(m_dst, dtype=torch.long))\n",
    "    data_dict[('movie', 'rated_by', 'user')] = (torch.tensor(m_dst, dtype=torch.long), torch.tensor(u_src, dtype=torch.long))\n",
    "    \n",
    "    # Movie-Attribute Edges\n",
    "    def build_attr_edges(df, col_name, map_dict, target_ntype, edge_name):\n",
    "        src_list = []\n",
    "        dst_list = []\n",
    "        for _, row in df.iterrows():\n",
    "            if row['ml_movie_id'] not in movie_map: continue\n",
    "            \n",
    "            mid = movie_map[row['ml_movie_id']]\n",
    "            try:\n",
    "                attr_ids = json.loads(row[col_name])\n",
    "                if isinstance(attr_ids, list):\n",
    "                    for aid in attr_ids:\n",
    "                        if aid in map_dict:\n",
    "                            src_list.append(mid)\n",
    "                            dst_list.append(map_dict[aid])\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        data_dict[('movie', f'has_{edge_name}', target_ntype)] = (\n",
    "            torch.tensor(src_list, dtype=torch.long), \n",
    "            torch.tensor(dst_list, dtype=torch.long)\n",
    "        )\n",
    "        data_dict[(target_ntype, f'{edge_name}_of', 'movie')] = (\n",
    "            torch.tensor(dst_list, dtype=torch.long), \n",
    "            torch.tensor(src_list, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "    print(\"Building knowledge edges...\")\n",
    "    build_attr_edges(movies_df, 'genres', genre_map, 'genre', 'genre')\n",
    "    build_attr_edges(movies_df, 'keywords', keyword_map, 'keyword', 'keyword')\n",
    "    build_attr_edges(movies_df, 'directors', director_map, 'director', 'director')\n",
    "    build_attr_edges(movies_df, 'writers', writer_map, 'writer', 'writer')\n",
    "\n",
    "    num_nodes_dict = {\n",
    "        'user': len(user_map), 'movie': len(movie_map),\n",
    "        'genre': len(genre_map), 'keyword': len(keyword_map),\n",
    "        'director': len(director_map), 'writer': len(writer_map)\n",
    "    }\n",
    "\n",
    "    g = dgl.heterograph(data_dict, num_nodes_dict=num_nodes_dict)\n",
    "    \n",
    "    # Store genre info for evaluation later\n",
    "    # Map movie_id -> set of genre names\n",
    "    movie_genres_dict = {}\n",
    "    # Need reverse genre map for names\n",
    "    id_to_genre_name = dict(zip(genres_df['id'], genres_df['name']))\n",
    "    \n",
    "    for _, row in movies_df.iterrows():\n",
    "        mid = str(row['ml_movie_id'])\n",
    "        try:\n",
    "            g_ids = json.loads(row['genres'])\n",
    "            names = {id_to_genre_name.get(gid, 'unknown') for gid in g_ids}\n",
    "            movie_genres_dict[mid] = names\n",
    "        except:\n",
    "            movie_genres_dict[mid] = set()\n",
    "\n",
    "    mappings = {\n",
    "        'user_map': user_map, 'movie_map': movie_map,\n",
    "        'id_to_user': id_to_user, 'id_to_movie': id_to_movie,\n",
    "        'movie_genres': movie_genres_dict\n",
    "    }\n",
    "    \n",
    "    return g, mappings, train_df, test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114393c0",
   "metadata": {},
   "source": [
    "## 2. Load & Align Text Embeddings\n",
    "This function aligns the loaded .pt file with the DGL Graph IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d03871eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_text_embeddings(movie_map, pt_file_path):\n",
    "    print(f\"Loading text embeddings from {pt_file_path}...\")\n",
    "    data = torch.load(pt_file_path)\n",
    "    \n",
    "    raw_movie_ids = data['movie_ids']\n",
    "    overview_embs = data['overview_embs']\n",
    "    review_embs = data['review_embs']\n",
    "    review_mask = data['review_mask']\n",
    "    \n",
    "    num_movies = len(movie_map)\n",
    "    emb_dim = overview_embs.shape[1]\n",
    "    max_reviews = review_embs.shape[1]\n",
    "    \n",
    "    # Create aligned tensors (Initialized to zero for missing movies)\n",
    "    aligned_overviews = torch.zeros((num_movies, emb_dim))\n",
    "    aligned_reviews = torch.zeros((num_movies, max_reviews, emb_dim))\n",
    "    aligned_mask = torch.zeros((num_movies, max_reviews))\n",
    "    \n",
    "    # Map data\n",
    "    hit_count = 0\n",
    "    for i, ml_id in enumerate(raw_movie_ids):\n",
    "        if ml_id in movie_map:\n",
    "            dgl_id = movie_map[ml_id]\n",
    "            aligned_overviews[dgl_id] = overview_embs[i]\n",
    "            aligned_reviews[dgl_id] = review_embs[i]\n",
    "            aligned_mask[dgl_id] = review_mask[i]\n",
    "            hit_count += 1\n",
    "            \n",
    "    print(f\"Aligned {hit_count}/{num_movies} movies with text data.\")\n",
    "    return aligned_overviews, aligned_reviews, aligned_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7312e084",
   "metadata": {},
   "source": [
    "## 2.1 Dataset & DataLoader\n",
    "Handles Negative Sampling: For every user-item pair (positive), sample a movie they haven't seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "173b2f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommendationDataset(Dataset):\n",
    "    def __init__(self, ratings_df, user_map, movie_map):\n",
    "        # Filter only valid users/items\n",
    "        self.data = []\n",
    "        valid_u = set(user_map.keys())\n",
    "        valid_m = set(movie_map.keys())\n",
    "        \n",
    "        # Group interactions for fast negative sampling\n",
    "        self.user_history = {}\n",
    "        \n",
    "        print(\"Indexing dataset...\")\n",
    "        for u, m, r in zip(ratings_df['user_id'], ratings_df['movie_id'], ratings_df['rating']):\n",
    "            if u in valid_u and m in valid_m:\n",
    "                u_id = user_map[u]\n",
    "                m_id = movie_map[m]\n",
    "                \n",
    "                # We typically train on all interactions, or just positive ones depending on strategy.\n",
    "                # BPR usually trains on Positives, and samples Negatives dynamically.\n",
    "                if r >= 4:\n",
    "                    self.data.append((u_id, m_id))\n",
    "                    \n",
    "                    if u_id not in self.user_history:\n",
    "                        self.user_history[u_id] = set()\n",
    "                    self.user_history[u_id].add(m_id)\n",
    "        \n",
    "        self.all_movie_ids = list(movie_map.values())\n",
    "        self.num_movies = len(self.all_movie_ids)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        user, pos_item = self.data[idx]\n",
    "        \n",
    "        # Negative Sampling\n",
    "        while True:\n",
    "            neg_item = np.random.randint(0, self.num_movies)\n",
    "            if neg_item not in self.user_history[user]:\n",
    "                break\n",
    "                \n",
    "        return torch.tensor(user), torch.tensor(pos_item), torch.tensor(neg_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166b673d",
   "metadata": {},
   "source": [
    "## 3. Relational Attentive Graph Conv\n",
    "This layer improves upon CompGCN by adding **Attention** (from GAT) and retaining the **Relation Embeddings** (from CompGCN).\n",
    "\n",
    "Logic:\n",
    "$h_{N(v)} = \\sum_{r \\in R} \\sum_{u \\in N_r(v)} \\alpha_{u,v} (h_u \\circ h_r)$\n",
    "where $\\alpha_{u,v}$ is the attention score computed over $(h_u, h_r, h_v)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecb359d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelationalAttentiveLayer(nn.Module):\n",
    "    def __init__(self, in_feat, out_feat, rel_names, num_heads=4, feat_drop=0.2):\n",
    "        super().__init__()\n",
    "        self.in_feat = in_feat\n",
    "        self.out_feat = out_feat\n",
    "        self.rel_names = rel_names\n",
    "        self.num_heads = num_heads\n",
    "        \n",
    "        # Relation Embeddings\n",
    "        self.rel_embedding = nn.ParameterDict({\n",
    "            rel: nn.Parameter(torch.randn(in_feat)) for rel in rel_names\n",
    "        })\n",
    "        \n",
    "        # Weights for GAT\n",
    "        # We transform (h+r) for src, and (h) for dst\n",
    "        self.W = nn.Linear(in_feat, out_feat * num_heads, bias=False)\n",
    "        \n",
    "        # Attention Vectors (Left and Right)\n",
    "        # a^T [Wh_i || Wh_j] = (a_l)^T Wh_i + (a_r)^T Wh_j\n",
    "        # \n",
    "        self.attn_l = nn.Parameter(torch.FloatTensor(size=(1, num_heads, out_feat)))\n",
    "        self.attn_r = nn.Parameter(torch.FloatTensor(size=(1, num_heads, out_feat)))\n",
    "        \n",
    "        self.feat_drop = nn.Dropout(feat_drop)\n",
    "        self.leaky_relu = nn.LeakyReLU(0.2)\n",
    "        \n",
    "        # Initialization\n",
    "        nn.init.xavier_uniform_(self.W.weight)\n",
    "        nn.init.xavier_uniform_(self.attn_l)\n",
    "        nn.init.xavier_uniform_(self.attn_r)\n",
    "\n",
    "    def forward(self, g, inputs):\n",
    "        funcs = {}\n",
    "        \n",
    "        for etype in g.canonical_etypes:\n",
    "            # Exract the information of the edge\n",
    "            src_type, rel, dst_type = etype\n",
    "            if src_type not in inputs or dst_type not in inputs: continue\n",
    "            \n",
    "            # Source node\n",
    "            h_src = inputs[src_type]\n",
    "            # Destination node\n",
    "            h_dst = inputs[dst_type]\n",
    "            r_emb = self.rel_embedding[rel]\n",
    "            \n",
    "            # Transform Features\n",
    "            # Add relation embedding to source\n",
    "            feat_src = self.W(h_src + r_emb).view(-1, self.num_heads, self.out_feat)\n",
    "            feat_dst = self.W(h_dst).view(-1, self.num_heads, self.out_feat)\n",
    "            \n",
    "            # Compute Attention Terms (Nodes)\n",
    "            # el = (feat_src * attn_l).sum\n",
    "            el = (feat_src * self.attn_l).sum(dim=-1).unsqueeze(-1)\n",
    "            er = (feat_dst * self.attn_r).sum(dim=-1).unsqueeze(-1)\n",
    "            \n",
    "            # Save to graph to compute edge attention\n",
    "            # We use unique keys per relation to avoid overwrites\n",
    "            g.nodes[src_type].data[f'ft_{rel}'] = feat_src\n",
    "            g.nodes[src_type].data[f'el_{rel}'] = el\n",
    "            g.nodes[dst_type].data[f'er_{rel}'] = er\n",
    "            \n",
    "            # Compute Attention Score (Edges)\n",
    "            # e = LeakyReLU(el + er)\n",
    "            # We must use apply_edges on the specific edge type\n",
    "            # We add another attribute to the edge called e_{rel} with the sum of both attention scores\n",
    "            g.apply_edges(fn.u_add_v(f'el_{rel}', f'er_{rel}', f'e_{rel}'), etype=etype)\n",
    "            \n",
    "            # Softmax (Normalize) -> This puts 'a' on edges\n",
    "            e = self.leaky_relu(g.edges[etype].data.pop(f'e_{rel}'))\n",
    "            g.edges[etype].data[f'a_{rel}'] = dgl.nn.functional.edge_softmax(g[etype], e)\n",
    "            \n",
    "            # Message Passing (Weighted Sum)\n",
    "            # Now 'a_{rel}' exists on the edge!\n",
    "            # Basically, we multiply the node representation with the attention score and send it as a message\n",
    "            funcs[etype] = (fn.u_mul_e(f'ft_{rel}', f'a_{rel}', 'm'), fn.sum('m', 'h_neigh'))\n",
    "            \n",
    "        g.multi_update_all(funcs, 'sum')\n",
    "        \n",
    "        new_features = {}\n",
    "        for ntype in g.ntypes:\n",
    "            if 'h_neigh' in g.nodes[ntype].data:\n",
    "                h = g.nodes[ntype].data.pop('h_neigh')\n",
    "                # We apply the leakyReLu to the mean of the sum of the attended features of its neighbours\n",
    "                new_features[ntype] = self.leaky_relu(h.mean(1))\n",
    "                \n",
    "        return new_features\n",
    "\n",
    "\n",
    "class ReviewAggregator(nn.Module):\n",
    "    def __init__(self, embed_dim):\n",
    "        super().__init__()\n",
    "        # Define a simple linear layer to project embeddings into a single scalar   \n",
    "        self.query = nn.Linear(embed_dim, 1)\n",
    "\n",
    "    def forward(self, review_embs, mask=None):\n",
    "        scores = self.query(review_embs)\n",
    "\n",
    "        # So that the amount of reviews is the same at the eyes of the tensor\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask.unsqueeze(-1) == 0, -1e9)\n",
    "\n",
    "        weights = F.softmax(scores, dim=1)\n",
    "        # Add the embeddings wheighted by the relevance score.\n",
    "        return (weights * review_embs).sum(dim=1)\n",
    "\n",
    "class GatedCrossAttention(nn.Module):\n",
    "    def __init__(self, dim, num_heads=4):\n",
    "        super().__init__()\n",
    "        self.mha = nn.MultiheadAttention(embed_dim=dim, num_heads=num_heads, batch_first=True)\n",
    "        self.gate = nn.Sequential(nn.Linear(dim * 2, dim), nn.Sigmoid())\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "    def forward(self, x_graph, x_text):\n",
    "        # We will use the graph representation as the query\n",
    "        q = x_graph.unsqueeze(1)\n",
    "        # And the text embeddings as keys and values\n",
    "        k = v = x_text.unsqueeze(1)\n",
    "        attn_out, _ = self.mha(q, k, v)\n",
    "        attn_out = attn_out.squeeze(1)\n",
    "\n",
    "        # Now, we put together both representations\n",
    "        concat = torch.cat([x_graph, attn_out], dim=-1)\n",
    "        # And let our simple layers output the alpha weight\n",
    "        alpha = self.gate(concat)\n",
    "\n",
    "        # We return the updated representation normalized for stabilized training\n",
    "        return self.norm(alpha * x_graph + (1 - alpha) * attn_out)\n",
    "\n",
    "class KnowledgeAwareRecommender(nn.Module):\n",
    "    def __init__(self, g, text_dim, hidden_dim, num_heads=4):\n",
    "        super().__init__()\n",
    "        self.g = g\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.node_embeds = nn.ModuleDict()\n",
    "        for ntype in g.ntypes:\n",
    "            # We initialize the embeddings?\n",
    "            self.node_embeds[ntype] = nn.Embedding(g.num_nodes(ntype), hidden_dim)\n",
    "        # First linear layer for text representations\n",
    "        self.text_proj = nn.Linear(text_dim, hidden_dim)\n",
    "\n",
    "        self.gnn = RelationalAttentiveLayer(hidden_dim, hidden_dim, g.etypes, num_heads)\n",
    "        self.review_agg = ReviewAggregator(hidden_dim)\n",
    "        self.fusion = GatedCrossAttention(hidden_dim, num_heads)\n",
    "        # Inference layers with final output 1 number\n",
    "        self.predict_layer = nn.Sequential(nn.Linear(hidden_dim * 2, 64), nn.ReLU(), nn.Linear(64, 1))\n",
    "        \n",
    "    def forward(self, g, users, items, ov, rev, mask):\n",
    "        # Graph Arm\n",
    "        h_dict = {ntype: self.node_embeds[ntype](g.nodes(ntype)) for ntype in g.ntypes}\n",
    "        # Apply the Attention layer to the nodes embeddings\n",
    "        # New dictionary has, for each entry, the attended features with leaky ReLu applied\n",
    "        h_dict = self.gnn(g, h_dict)\n",
    "        # ??\n",
    "        u_graph = h_dict['user'][users]\n",
    "        i_graph = h_dict['movie'][items]\n",
    "        \n",
    "        # Text Arm\n",
    "        # The text projection of the overview\n",
    "        feat_ov = self.text_proj(ov)\n",
    "        # Same for the reviews\n",
    "        feat_rev = self.text_proj(rev)\n",
    "        # We have many reviews, aggregate them\n",
    "        agg_rev = self.review_agg(feat_rev, mask)\n",
    "        # Add and normalize information\n",
    "        i_text = (feat_ov + agg_rev) / 2\n",
    "        \n",
    "        # Fusion\n",
    "        i_fused = self.fusion(i_graph, i_text)\n",
    "        \n",
    "        # Prediction\n",
    "        x = torch.cat([u_graph, i_fused], dim=-1)\n",
    "        return self.predict_layer(x), u_graph, i_graph, i_text\n",
    "    \n",
    "    def get_all_embeddings(self, g, all_ov, all_rev, all_mask):\n",
    "        \"\"\"Computes embeddings for ALL users and ALL items once.\"\"\"\n",
    "        with torch.no_grad():\n",
    "            # Graph Embeddings for everyone\n",
    "            h_dict = {ntype: self.node_embeds[ntype](g.nodes(ntype)) for ntype in g.ntypes}\n",
    "            h_dict = self.gnn(g, h_dict)\n",
    "            u_all = h_dict['user']\n",
    "            i_graph_all = h_dict['movie']\n",
    "            \n",
    "            # Text Embeddings for all items\n",
    "            feat_ov = self.text_proj(all_ov)\n",
    "            feat_rev = self.text_proj(all_rev)\n",
    "            agg_rev = self.review_agg(feat_rev, all_mask)\n",
    "            i_text_all = (feat_ov + agg_rev) / 2\n",
    "            \n",
    "            # Fusion for all items\n",
    "            i_fused_all = self.fusion(i_graph_all, i_text_all)\n",
    "            \n",
    "            return u_all, i_fused_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4358f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_eval_data(train_df, test_df, movies_df, mappings):\n",
    "    \"\"\"\n",
    "    Constructs the 4 data structures required for evaluation.\n",
    "    \"\"\"\n",
    "    print(\"Constructing Evaluation Dictionaries...\")\n",
    "    \n",
    "    # Ground Truth: {user_id (str): {item_id (str): rating}}\n",
    "    # Using Test Set\n",
    "    ground_truth = (test_df[test_df['rating'] >= 4] # Only positive interactions\n",
    "                    .groupby('user_id')\n",
    "                    .apply(lambda x: dict(zip(x['movie_id'].astype(str), x['rating'])))\n",
    "                    .to_dict())\n",
    "    ground_truth = {str(k): v for k, v in ground_truth.items()}\n",
    "    \n",
    "    # Item Popularity: {item_id (str): count}\n",
    "    # Using Training Set\n",
    "    item_popularity = train_df.groupby('movie_id')['rating'].count().to_dict()\n",
    "    item_popularity = {str(k): v for k, v in item_popularity.items()}\n",
    "    \n",
    "    # Item Features: {item_id (str): {feature, ...}}\n",
    "    # Using Genre dictionary created during graph load\n",
    "    item_features = mappings['movie_genres']\n",
    "    \n",
    "    # All Items: Set of strings\n",
    "    all_items = set(str(m) for m in mappings['movie_map'].keys())\n",
    "    \n",
    "    return ground_truth, item_popularity, item_features, all_items\n",
    "\n",
    "def generate_recommendations(model, g, mappings, ov_data, rev_data, mask_data, train_df, k=50):\n",
    "    \"\"\"\n",
    "    Generates Top-K recommendations for users in the Test Set.\n",
    "    Returns: Dict {user_id (str): [item_id (str), ...]}\n",
    "    \"\"\"\n",
    "    print(\"Generating Recommendations...\")\n",
    "    model.eval()\n",
    "    \n",
    "    user_map = mappings['user_map']\n",
    "    id_to_movie = mappings['id_to_movie']\n",
    "    \n",
    "    # Precompute all embeddings\n",
    "    u_all_emb, i_all_emb = model.get_all_embeddings(g, ov_data, rev_data, mask_data)\n",
    "    \n",
    "    # Identify Users to Recommend For (Test Users)\n",
    "    test_users = list(mappings['id_to_user'].keys()) # Predict for everyone or just test subset\n",
    "    \n",
    "    # Build History (to filter seen items)\n",
    "    # We must filter items seen in TRAIN so we don't recommend them again\n",
    "    user_history = train_df.groupby('user_id')['movie_id'].apply(set).to_dict()\n",
    "    \n",
    "    recommendations = {}\n",
    "    \n",
    "    # Process in chunks to avoid OOM if N_users * N_items is too large\n",
    "    # Since N=6000, M=1600, NxM ~ 9.6M floats, fits in memory easily.\n",
    "    \n",
    "    BATCH_USERS = 100\n",
    "    num_items = i_all_emb.shape[0]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(test_users), BATCH_USERS)):\n",
    "            batch_u_idxs = test_users[i : i + BATCH_USERS]\n",
    "            \n",
    "            # Get User Embeddings: (Batch, Hidden)\n",
    "            batch_u_emb = u_all_emb[batch_u_idxs]\n",
    "            \n",
    "            # Score against ALL items\n",
    "            # We replicate items for each user -> (Batch, Num_Items, Hidden * 2)\n",
    "            # Or better: (Batch, 1, H) concat (1, Num_Items, H) -> Broadcast\n",
    "            \n",
    "            # Expand for broadcasting\n",
    "            # U: (Batch, 1, H)\n",
    "            u_exp = batch_u_emb.unsqueeze(1).expand(-1, num_items, -1)\n",
    "            # I: (1, Num_Items, H)\n",
    "            i_exp = i_all_emb.unsqueeze(0).expand(len(batch_u_idxs), -1, -1)\n",
    "            \n",
    "            # Concat\n",
    "            x = torch.cat([u_exp, i_exp], dim=-1) # (Batch, Num_Items, H*2)\n",
    "            \n",
    "            # Score via MLP\n",
    "            # Flatten, pass through linear, reshape\n",
    "            scores = model.predict_layer(x).squeeze(-1) # (Batch, Num_Items)\n",
    "            \n",
    "            # Get Top K\n",
    "            # We ask for k + seen_count to ensure we have enough after filtering\n",
    "            # But simple logic: just argsort descending\n",
    "            _, top_indices = torch.sort(scores, dim=1, descending=True)\n",
    "            top_indices = top_indices.cpu().numpy()\n",
    "            \n",
    "            # Filter and Store\n",
    "            for j, u_idx_dgl in enumerate(batch_u_idxs):\n",
    "                real_u_id = str(mappings['id_to_user'][u_idx_dgl])\n",
    "                seen = user_history.get(int(real_u_id), set())\n",
    "                \n",
    "                recs = []\n",
    "                for item_idx in top_indices[j]:\n",
    "                    real_item_id = id_to_movie[item_idx]\n",
    "                    if real_item_id not in seen:\n",
    "                        recs.append(str(real_item_id))\n",
    "                        if len(recs) == k:\n",
    "                            break\n",
    "                \n",
    "                recommendations[real_u_id] = recs\n",
    "                \n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2d0f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Building User-Movie edges...\n",
      "Building knowledge edges...\n",
      "Loading text embeddings from ../data/processed/movie_text_embeddings.pt...\n",
      "Aligned 1638/1638 movies with text data.\n",
      "Indexing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_93007/3823026092.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(pt_file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 342/342 [08:07<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.5046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 342/342 [02:56<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 0.3616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 342/342 [02:52<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 0.3292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 342/342 [02:53<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 0.3032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 342/342 [03:20<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 0.2902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 342/342 [03:23<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 0.2830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 342/342 [03:40<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Loss: 0.2749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 342/342 [03:35<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Loss: 0.2689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 342/342 [03:08<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Loss: 0.2580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 342/342 [03:05<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Loss: 0.2473\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def bpr_loss(pos_scores, neg_scores):\n",
    "    return -torch.mean(torch.log(torch.sigmoid(pos_scores - neg_scores)))\n",
    "\n",
    "def infonce_loss(graph_emb, text_emb, temperature=0.1):\n",
    "    graph_emb = F.normalize(graph_emb, dim=1)\n",
    "    text_emb = F.normalize(text_emb, dim=1)\n",
    "    logits = torch.matmul(graph_emb, text_emb.T) / temperature\n",
    "    labels = torch.arange(logits.shape[0]).to(logits.device)\n",
    "    return F.cross_entropy(logits, labels)\n",
    "\n",
    "\n",
    "# Load Data\n",
    "g, mappings, train_df, test_df = load_data_and_build_graph()\n",
    "g = g.to(device)\n",
    "\n",
    "# Load Text\n",
    "ov_data, rev_data, mask_data = align_text_embeddings(mappings['movie_map'], TEXT_EMBED_PATH)\n",
    "ov_data, rev_data, mask_data = ov_data.to(device), rev_data.to(device), mask_data.to(device)\n",
    "\n",
    "# Setup Loader\n",
    "dataset = RecommendationDataset(train_df, mappings['user_map'], mappings['movie_map'])\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Initialize Model\n",
    "text_dim = ov_data.shape[1]\n",
    "model = KnowledgeAwareRecommender(g, text_dim, HIDDEN_DIM, ATTENTION_HEADS).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# Training\n",
    "print(\"Starting Training...\")\n",
    "loss_history = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for users, pos_items, neg_items in tqdm(dataloader, desc=f\"Epoch {epoch+1}\"):\n",
    "        users, pos_items, neg_items = users.to(device), pos_items.to(device), neg_items.to(device)\n",
    "        \n",
    "        # Get batch text\n",
    "        pos_ov, pos_rev, pos_mask = ov_data[pos_items], rev_data[pos_items], mask_data[pos_items]\n",
    "        neg_ov, neg_rev, neg_mask = ov_data[neg_items], rev_data[neg_items], mask_data[neg_items]\n",
    "        \n",
    "        # Forward\n",
    "        pos_scores, _, pos_i_g, pos_i_t = model(g, users, pos_items, pos_ov, pos_rev, pos_mask)\n",
    "        neg_scores, _, _, _ = model(g, users, neg_items, neg_ov, neg_rev, neg_mask)\n",
    "        \n",
    "        loss = bpr_loss(pos_scores, neg_scores) + 0.1 * infonce_loss(pos_i_g, pos_i_t)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    loss_history.append(avg_loss)\n",
    "    print(f\"Epoch {epoch+1} Loss: {avg_loss:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(loss_history, marker='o', linestyle='-', color='b')\n",
    "plt.title('Training Loss over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215e7ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Recommendations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 12.52it/s]\n",
      "/tmp/ipykernel_93007/2574588468.py:11: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: dict(zip(x['movie_id'].astype(str), x['rating'])))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing Evaluation Dictionaries...\n",
      "\n",
      "--- Evaluation Structures Ready ---\n",
      "Recommendations: 943 users\n",
      "Ground Truth: 456 users\n",
      "Popularity Dict: 1650 items\n",
      "Item Features: 1638 items\n",
      "\n",
      "============================================================\n",
      "RECOMMENDATION EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "CATALOG COVERAGE:\n",
      "  @10: 0.1575\n",
      "  @20: 0.2192\n",
      "  @50: 0.3498\n",
      "\n",
      "F1:\n",
      "  @10: 0.2024\n",
      "  @20: 0.2216\n",
      "  @50: 0.2196\n",
      "\n",
      "INTRA LIST SIMILARITY:\n",
      "  @10: 1.0000\n",
      "  @20: 1.0000\n",
      "  @50: 1.0000\n",
      "\n",
      "MAP:\n",
      "  @10: 0.4867\n",
      "  @20: 0.4375\n",
      "  @50: 0.3634\n",
      "\n",
      "MRR:\n",
      "  @10: 0.5691\n",
      "  @20: 0.5742\n",
      "  @50: 0.5757\n",
      "\n",
      "NDCG:\n",
      "  @10: 0.3489\n",
      "  @20: 0.3434\n",
      "  @50: 0.3694\n",
      "\n",
      "NOVELTY:\n",
      "  @10: 8.3365\n",
      "  @20: 8.5232\n",
      "  @50: 8.8253\n",
      "\n",
      "PRECISION:\n",
      "  @10: 0.2987\n",
      "  @20: 0.2501\n",
      "  @50: 0.1804\n",
      "\n",
      "RECALL:\n",
      "  @10: 0.1676\n",
      "  @20: 0.2607\n",
      "  @50: 0.4317\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Generate Evaluation Data\n",
    "recs = generate_recommendations(model, g, mappings, ov_data, rev_data, mask_data, train_df, k=50)\n",
    "\n",
    "# Eval Structures\n",
    "gt, pop, feats, all_items = prepare_eval_data(train_df, test_df, pd.read_csv('../data/processed/movies_graph_ready.csv'), mappings)\n",
    "\n",
    "print(\"\\n--- Evaluation Structures Ready ---\")\n",
    "print(f\"Recommendations: {len(recs)} users\")\n",
    "print(f\"Ground Truth: {len(gt)} users\")\n",
    "print(f\"Popularity Dict: {len(pop)} items\")\n",
    "print(f\"Item Features: {len(feats)} items\")\n",
    "\n",
    "\n",
    "results = evaluate_recommendations(recs, gt, [10, 20, 50], pop, feats, all_items)\n",
    "print_evaluation_results(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
