{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90467fb4",
   "metadata": {},
   "source": [
    "# Modelos Baseline\n",
    "\n",
    "En este notebook se implementaran los modelos baseline del proyecto y se guardaran las métricas con el mismo dataset que se utilizará para el modelo principal para hacer bentchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a77d9a3",
   "metadata": {},
   "source": [
    "## Lectura de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93c4216e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils.recomender_metrics import prepare_ground_truth, evaluate_recommendations, print_evaluation_results\n",
    "from collections import defaultdict\n",
    "import pyreclab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f6e7c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '../data/processed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfd7acc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Head:\n",
      "   movieId  item_id  imdbId  tmdbId  user_id  rating  timestamp\n",
      "0        1        1  114709   862.0        1       5  874965758\n",
      "1        1        1  114709   862.0        2       4  888550871\n",
      "2        1        1  114709   862.0        6       4  883599478\n",
      "3        1        1  114709   862.0       13       3  882140487\n",
      "4        1        1  114709   862.0       16       5  877717833\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(f'{data_folder}processed_train.csv', encoding='latin-1', header=0)\n",
    "test_df = pd.read_csv(f'{data_folder}processed_test.csv', encoding='latin-1', header=0)\n",
    "\n",
    "train_df['rating'] = train_df['rating'].astype(int)\n",
    "test_df['rating'] = test_df['rating'].astype(int)\n",
    "\n",
    "train_df['rating'] = pd.to_numeric(train_df['rating'], errors='coerce').astype('Int64')\n",
    "test_df['rating'] = pd.to_numeric(test_df['rating'], errors='coerce').astype('Int64')\n",
    "\n",
    "print(\"Training Data Head:\")\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60356264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Movie Data Head:\n",
      "   movieId                               title  item_id release_date  unknown  \\\n",
      "0        1                    Toy Story (1995)        1  01-Jan-1995        0   \n",
      "1        2                      Jumanji (1995)      755  01-Jan-1995        0   \n",
      "2        3             Grumpier Old Men (1995)     1028  01-Jan-1995        0   \n",
      "3        4            Waiting to Exhale (1995)     1311  15-Jan-1996        0   \n",
      "4        5  Father of the Bride Part II (1995)      756  01-Jan-1995        0   \n",
      "\n",
      "   Action  Adventure  Animation  Children's  Comedy  ...  Horror  Musical  \\\n",
      "0       0          0          1           1       1  ...       0        0   \n",
      "1       1          1          0           1       0  ...       0        0   \n",
      "2       0          0          0           0       1  ...       0        0   \n",
      "3       0          0          0           0       1  ...       0        0   \n",
      "4       0          0          0           0       1  ...       0        0   \n",
      "\n",
      "   Mystery  Romance  Sci-Fi  Thriller  War  Western  imdbId   tmdbId  \n",
      "0        0        0       0         0    0        0  114709    862.0  \n",
      "1        0        0       1         0    0        0  113497   8844.0  \n",
      "2        0        1       0         0    0        0  113228  15602.0  \n",
      "3        0        0       0         0    0        0  114885  31357.0  \n",
      "4        0        0       0         0    0        0  113041  11862.0  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "movies_df = pd.read_csv(f'{data_folder}processed_movies.csv', encoding='latin-1', header=0)\n",
    "\n",
    "print(\"\\nMovie Data Head:\")\n",
    "print(movies_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102d0b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User Data Head:\n",
      "   user_id  age gender  occupation zip_code  mood_dark  mood_emotional  \\\n",
      "0        1   24      M  technician    85711   0.034632        0.212121   \n",
      "1        2   53      F       other    94043   0.014706        0.308824   \n",
      "2        3   23      M      writer    32067   0.000000        0.288462   \n",
      "3        4   24      M  technician    43537   0.041667        0.125000   \n",
      "4        5   33      F       other    15213   0.028986        0.123188   \n",
      "\n",
      "   mood_exciting  mood_family-friendly  mood_intense  mood_lighthearted  \\\n",
      "0       0.121212              0.073593      0.099567           0.259740   \n",
      "1       0.102941              0.044118      0.147059           0.161765   \n",
      "2       0.192308              0.019231      0.269231           0.153846   \n",
      "3       0.375000              0.000000      0.375000           0.083333   \n",
      "4       0.181159              0.123188      0.137681           0.275362   \n",
      "\n",
      "   mood_neutral  mood_relaxing  mood_romantic  mood_suspenseful  \\\n",
      "0      0.012987       0.008658       0.116883          0.008658   \n",
      "1      0.014706       0.000000       0.191176          0.000000   \n",
      "2      0.000000       0.000000       0.057692          0.000000   \n",
      "3      0.000000       0.000000       0.000000          0.000000   \n",
      "4      0.000000       0.007246       0.086957          0.036232   \n",
      "\n",
      "   mood_thoughtful  mood_uplifting  \n",
      "0         0.047619        0.004329  \n",
      "1         0.014706        0.000000  \n",
      "2         0.019231        0.000000  \n",
      "3         0.000000        0.000000  \n",
      "4         0.000000        0.000000  \n"
     ]
    }
   ],
   "source": [
    "users_df = pd.read_csv(f'{data_folder}users_with_moods.csv', encoding='latin-1', header=0)\n",
    "\n",
    "print(\"\\nUser Data Head:\")\n",
    "print(users_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671230b7",
   "metadata": {},
   "source": [
    "## Estructuras para métricas\n",
    "\n",
    "Para calcular las métricas, necesitamos saber, por ejemplo, el `ground truth` o la popularidad de los items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5933e90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3017834/983717880.py:12: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: dict(zip(x['item_id'].astype(str), x['rating'])))\n"
     ]
    }
   ],
   "source": [
    "i_cols = [\n",
    "    'unknown', 'Action', 'Adventure', 'Animation', 'Children\\'s', 'Comedy',\n",
    "    'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror',\n",
    "    'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western'\n",
    "]\n",
    "\n",
    "# Agrupamos el DataFrame de test por usuario y convertimos los item_id de cada grupo en un conjunto (set)\n",
    "ground_truth_old = test_df[test_df['rating'] > 2].groupby('user_id')['item_id'].apply(set).to_dict()\n",
    "\n",
    "ground_truth = (test_df[test_df['rating'] >= 2]\n",
    "                        .groupby('user_id')\n",
    "                        .apply(lambda x: dict(zip(x['item_id'].astype(str), x['rating'])))\n",
    "                        .to_dict())\n",
    "ground_truth = {str(k): v for k, v in ground_truth.items()}\n",
    "\n",
    "k_values = [10, 20, 50]\n",
    "\n",
    "# Contamos popularidad como suma de ratings para dar más peso a los items mejor puntuados\n",
    "item_popularity = train_df.groupby('item_id')['rating'].sum().to_dict()\n",
    "\n",
    "# Creamos el diccionario iterando sobre el dataframe de películas\n",
    "item_features = {}\n",
    "for index, row in movies_df.iterrows():\n",
    "    item_id = row['item_id']\n",
    "    # Creamos un conjunto con los nombres de las columnas de género donde el valor es 1\n",
    "    genres = {genre for genre in i_cols if row[genre] == 1}\n",
    "    item_features[item_id] = genres\n",
    "\n",
    "all_items = set(movies_df['item_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9678c8",
   "metadata": {},
   "source": [
    "## Random model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7e832b",
   "metadata": {},
   "source": [
    "Generaremos, para cada usuario, aleatoriamente una lista de hasta 50 recomendaciones para poder evaluar las métricas a distintos puntos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e2e44de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener todos los IDs de películas únicos\n",
    "all_movie_ids = movies_df['item_id'].unique().tolist()\n",
    "\n",
    "# Crear el diccionario de ítems vistos por usuario (SOLO con datos de entrenamiento)\n",
    "user_seen_items = train_df.groupby('user_id')['item_id'].apply(set).to_dict()\n",
    "\n",
    "# Obtener la lista de usuarios para los que generaremos recomendaciones\n",
    "users_in_train = train_df['user_id'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efbb53ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de películas: 1195\n",
      "Total de usuarios en el set de entrenamiento: 943\n",
      "Películas vistas por el usuario 1: {1, 2, 3, 4, 5, 8, 9, 13, 15, 16, 21, 22, 25, 26, 28, 29, 32, 34, 35, 37, 38, 40, 41, 42, 43, 46, 48, 52, 57, 58, 63, 66, 68, 71, 77, 79, 83, 87, 88, 89, 93, 94, 95, 99, 101, 105, 106, 109, 110, 111, 116, 119, 122, 123, 124, 126, 127, 131, 133, 135, 136, 137, 138, 139, 141, 142, 144, 147, 149, 152, 153, 156, 158, 162, 165, 166, 167, 173, 176, 178, 179, 187, 191, 192, 194, 195, 197, 199, 203, 204, 205, 207, 216, 220, 223, 231, 234, 237, 238, 239, 244, 245, 246, 247, 249, 261, 263, 268, 269, 270, 271}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total de películas: {len(all_movie_ids)}\")\n",
    "print(f\"Total de usuarios en el set de entrenamiento: {len(users_in_train)}\")\n",
    "print(f\"Películas vistas por el usuario 1: {user_seen_items[1]}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42db2de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70151 17611\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df), len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "097a9e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_recommendations(users_to_recommend, all_movie_ids, user_seen_items, max_recommendations=50, random_state=42):\n",
    "    \"\"\"\n",
    "    Genera recomendaciones aleatorias para una lista de usuarios,\n",
    "    asegurándose de no recomendar ítems que ya han visto.\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    recommendations = {}\n",
    "    \n",
    "    for user_id in users_to_recommend:\n",
    "        # Obtener el conjunto de ítems que el usuario ya ha visto (del diccionario)\n",
    "        seen_items = user_seen_items.get(user_id, set())\n",
    "        \n",
    "        # Calcular los ítems candidatos (todos menos los ya vistos)\n",
    "        candidate_items = list(set(all_movie_ids) - seen_items)\n",
    "        \n",
    "        # Determinar cuántas recomendaciones generar\n",
    "        n_recommendations = min(max_recommendations, len(candidate_items))\n",
    "        \n",
    "        # Si hay candidatos, seleccionar aleatoriamente\n",
    "        if n_recommendations > 0:\n",
    "            recommended_items = np.random.choice(candidate_items, size=n_recommendations, replace=False).tolist()\n",
    "            recommendations[user_id] = recommended_items\n",
    "        else:\n",
    "            # En el caso improbable de que un usuario haya visto todo\n",
    "            recommendations[user_id] = []\n",
    "            \n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7d3a74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_recs = generate_random_recommendations(\n",
    "    users_to_recommend=users_in_train,\n",
    "    all_movie_ids=all_movie_ids,\n",
    "    user_seen_items=user_seen_items,\n",
    "    max_recommendations=50, # Generar hasta 50 recomendaciones por usuario\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a55a9f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RECOMMENDATION EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "CATALOG COVERAGE:\n",
      "  @10: 0.9992\n",
      "  @20: 1.0000\n",
      "  @50: 1.0000\n",
      "\n",
      "F1:\n",
      "  @10: 0.0467\n",
      "  @20: 0.0472\n",
      "  @50: 0.0504\n",
      "\n",
      "INTRA LIST SIMILARITY:\n",
      "  @10: 0.1671\n",
      "  @20: 0.1691\n",
      "  @50: 0.1680\n",
      "\n",
      "MAP:\n",
      "  @10: 0.0860\n",
      "  @20: 0.0861\n",
      "  @50: 0.0773\n",
      "\n",
      "MRR:\n",
      "  @10: 0.0935\n",
      "  @20: 0.1023\n",
      "  @50: 0.1095\n",
      "\n",
      "NDCG:\n",
      "  @10: 0.0371\n",
      "  @20: 0.0365\n",
      "  @50: 0.0440\n",
      "\n",
      "NOVELTY:\n",
      "  @10: 11.4614\n",
      "  @20: 11.4797\n",
      "  @50: 11.4904\n",
      "\n",
      "PRECISION:\n",
      "  @10: 0.0355\n",
      "  @20: 0.0330\n",
      "  @50: 0.0335\n",
      "\n",
      "RECALL:\n",
      "  @10: 0.0090\n",
      "  @20: 0.0172\n",
      "  @50: 0.0459\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Run evaluation\n",
    "results = evaluate_recommendations(\n",
    "    recommendations=random_recs,\n",
    "    ground_truth=ground_truth,\n",
    "    k_values=k_values,\n",
    "    item_popularity=item_popularity,\n",
    "    all_items=all_items,\n",
    "    item_features=item_features\n",
    ")\n",
    "\n",
    "print_evaluation_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f0683f",
   "metadata": {},
   "source": [
    "## Most popular items\n",
    "\n",
    "En este caso, todas las recomendaciones seran iguales para todos los usuarios: recomendaremos las 50 películas más populares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea8acf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agarramos el diccionario de popularidad y sacamos las 50 peliculas mas populares\n",
    "most_popular_items = sorted(item_popularity, key=item_popularity.get, reverse=True)\n",
    "most_popular_items = most_popular_items[:50]\n",
    "\n",
    "# Ahora llenamos las recomendaciones con las mismas peliculas para todos los usuarios\n",
    "pop_recs = {user_id: most_popular_items for user_id in users_in_train}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3587d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RECOMMENDATION EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "CATALOG COVERAGE:\n",
      "  @10: 0.0084\n",
      "  @20: 0.0167\n",
      "  @50: 0.0418\n",
      "\n",
      "F1:\n",
      "  @10: 0.1162\n",
      "  @20: 0.1291\n",
      "  @50: 0.1526\n",
      "\n",
      "INTRA LIST SIMILARITY:\n",
      "  @10: 0.1663\n",
      "  @20: 0.1748\n",
      "  @50: 0.1717\n",
      "\n",
      "MAP:\n",
      "  @10: 0.3470\n",
      "  @20: 0.3099\n",
      "  @50: 0.2492\n",
      "\n",
      "MRR:\n",
      "  @10: 0.4030\n",
      "  @20: 0.4093\n",
      "  @50: 0.4112\n",
      "\n",
      "NDCG:\n",
      "  @10: 0.1986\n",
      "  @20: 0.1958\n",
      "  @50: 0.2249\n",
      "\n",
      "NOVELTY:\n",
      "  @10: 7.4730\n",
      "  @20: 7.6388\n",
      "  @50: 7.9237\n",
      "\n",
      "PRECISION:\n",
      "  @10: 0.1845\n",
      "  @20: 0.1610\n",
      "  @50: 0.1376\n",
      "\n",
      "RECALL:\n",
      "  @10: 0.0801\n",
      "  @20: 0.1263\n",
      "  @50: 0.2447\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Run evaluation\n",
    "results = evaluate_recommendations(\n",
    "    recommendations=pop_recs,\n",
    "    ground_truth=ground_truth,\n",
    "    k_values=k_values,\n",
    "    item_popularity=item_popularity,\n",
    "    all_items=all_items,\n",
    "    item_features=item_features\n",
    ")\n",
    "\n",
    "print_evaluation_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e20753",
   "metadata": {},
   "source": [
    "## SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd911346",
   "metadata": {},
   "source": [
    "En concreto, implementaremos una FunkSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf903ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Porcesamos nuestros archivos para poder utilizar el objecto SVD de pyreclab\n",
    "\n",
    "pyreclab_test = test_df[['user_id', 'item_id', 'rating']].drop_duplicates()\n",
    "pyreclab_train = train_df[['user_id', 'item_id', 'rating']].drop_duplicates()\n",
    "\n",
    "pyreclab_test.to_csv(f'{data_folder}pyreclab_format/test.csv', index=False)\n",
    "pyreclab_train.to_csv(f'{data_folder}pyreclab_format/train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4afbc513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Constructor signature used is deprecated. From now on, it should include 'factors' parameter. See documentation for more information.\n",
      "Warning: Train signature used is deprecated. From now on, 'factors' parameter should be provided in model's constructor. See documentation for more information.\n"
     ]
    }
   ],
   "source": [
    "# Definicion de objeto svd\n",
    "svd = pyreclab.SVD(dataset=f'{data_folder}pyreclab_format/train.csv',\n",
    "                   dlmchar=b',',\n",
    "                   header=True,\n",
    "                   usercol=0,\n",
    "                   itemcol=1,\n",
    "                   ratingcol=2)\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "svd.train(factors=100, maxiter=100, lr=0.01, lamb=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd956662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.7294387105186461\n",
      "RMSE: 0.9231182101385945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: item id '814' was not included in training set\n"
     ]
    }
   ],
   "source": [
    "predlist, mae, rmse = svd.test(input_file=f'{data_folder}pyreclab_format/test.csv',\n",
    "                               dlmchar=b',',\n",
    "                               header=True,\n",
    "                               usercol=0,\n",
    "                               itemcol=1,\n",
    "                               ratingcol=2)\n",
    "\n",
    "print('MAE: {}\\nRMSE: {}'.format(mae, rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8d388cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.1604530144034825\n",
      "NDCG@50: 0.1251875103473805\n"
     ]
    }
   ],
   "source": [
    "# Testing de recomendaciones\n",
    "top_n = 50\n",
    "\n",
    "recommendList, maprec, ndcg = svd.testrec(input_file=f'{data_folder}pyreclab_format/test.csv',\n",
    "                                          dlmchar=b',',\n",
    "                                          header=True,\n",
    "                                          usercol=0,\n",
    "                                          itemcol=1,\n",
    "                                          ratingcol=2,\n",
    "                                          topn=top_n,\n",
    "                                          relevance_threshold=2,\n",
    "                                          includeRated=False)\n",
    "\n",
    "print('MAP: {}\\nNDCG@{}: {}'.format(maprec, top_n, ndcg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e952ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendList_int = {\n",
    "    int(user_id): [int(item_id) for item_id in items]\n",
    "    for user_id, items in recommendList.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b9ba099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RECOMMENDATION EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "CATALOG COVERAGE:\n",
      "  @10: 0.2117\n",
      "  @20: 0.3063\n",
      "  @50: 0.4519\n",
      "\n",
      "F1:\n",
      "  @10: 0.0777\n",
      "  @20: 0.0985\n",
      "  @50: 0.1125\n",
      "\n",
      "INTRA LIST SIMILARITY:\n",
      "  @10: 0.2555\n",
      "  @20: 0.2313\n",
      "  @50: 0.2094\n",
      "\n",
      "MAP:\n",
      "  @10: 0.1995\n",
      "  @20: 0.1843\n",
      "  @50: 0.1605\n",
      "\n",
      "MRR:\n",
      "  @10: 0.2156\n",
      "  @20: 0.2252\n",
      "  @50: 0.2302\n",
      "\n",
      "NDCG:\n",
      "  @10: 0.1070\n",
      "  @20: 0.1125\n",
      "  @50: 0.1252\n",
      "\n",
      "NOVELTY:\n",
      "  @10: 10.1562\n",
      "  @20: 10.0792\n",
      "  @50: 10.1439\n",
      "\n",
      "PRECISION:\n",
      "  @10: 0.1035\n",
      "  @20: 0.1050\n",
      "  @50: 0.0918\n",
      "\n",
      "RECALL:\n",
      "  @10: 0.0286\n",
      "  @20: 0.0582\n",
      "  @50: 0.1274\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_recommendations(\n",
    "    recommendations=recommendList_int,\n",
    "    ground_truth=ground_truth,\n",
    "    k_values=k_values,\n",
    "    item_popularity=item_popularity,\n",
    "    all_items=all_items,\n",
    "    item_features=item_features\n",
    ")\n",
    "\n",
    "print_evaluation_results(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
