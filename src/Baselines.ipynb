{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90467fb4",
   "metadata": {},
   "source": [
    "# Modelos Baseline\n",
    "\n",
    "En este notebook se implementaran los modelos baseline del proyecto y se guardaran las métricas con el mismo dataset que se utilizará para el modelo principal para hacer bentchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a77d9a3",
   "metadata": {},
   "source": [
    "## Lectura de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "93c4216e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils.recomender_metrics import prepare_ground_truth, evaluate_recommendations, print_evaluation_results\n",
    "from collections import defaultdict\n",
    "from utils.UKnn import UserKNN, calculate_mae, calculate_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4f6e7c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '../data/raw/ml-100k/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cfd7acc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Head:\n",
      "   user_id  item_id  rating  timestamp\n",
      "0        1        1       5  874965758\n",
      "1        1        2       3  876893171\n",
      "2        1        3       4  878542960\n",
      "3        1        4       3  876893119\n",
      "4        1        5       3  889751712\n"
     ]
    }
   ],
   "source": [
    "r_cols = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "\n",
    "# Read the training and testing sets\n",
    "train_df = pd.read_csv(f'{data_folder}u1.base', sep='\\t', names=r_cols, encoding='latin-1')\n",
    "test_df = pd.read_csv(f'{data_folder}u1.test', sep='\\t', names=r_cols, encoding='latin-1')\n",
    "\n",
    "train_df['rating'] = train_df['rating'].astype(int)\n",
    "test_df['rating'] = test_df['rating'].astype(int)\n",
    "\n",
    "train_df['rating'] = pd.to_numeric(train_df['rating'], errors='coerce').astype('Int64')\n",
    "test_df['rating'] = pd.to_numeric(test_df['rating'], errors='coerce').astype('Int64')\n",
    "\n",
    "print(\"Training Data Head:\")\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "60356264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Movie Data Head:\n",
      "   item_id              title release_date  video_release_date  \\\n",
      "0        1   Toy Story (1995)  01-Jan-1995                 NaN   \n",
      "1        2   GoldenEye (1995)  01-Jan-1995                 NaN   \n",
      "2        3  Four Rooms (1995)  01-Jan-1995                 NaN   \n",
      "3        4  Get Shorty (1995)  01-Jan-1995                 NaN   \n",
      "4        5     Copycat (1995)  01-Jan-1995                 NaN   \n",
      "\n",
      "                                            IMDb_URL  unknown  Action  \\\n",
      "0  http://us.imdb.com/M/title-exact?Toy%20Story%2...        0       0   \n",
      "1  http://us.imdb.com/M/title-exact?GoldenEye%20(...        0       1   \n",
      "2  http://us.imdb.com/M/title-exact?Four%20Rooms%...        0       0   \n",
      "3  http://us.imdb.com/M/title-exact?Get%20Shorty%...        0       1   \n",
      "4  http://us.imdb.com/M/title-exact?Copycat%20(1995)        0       0   \n",
      "\n",
      "   Adventure  Animation  Children's  ...  Fantasy  Film-Noir  Horror  Musical  \\\n",
      "0          0          1           1  ...        0          0       0        0   \n",
      "1          1          0           0  ...        0          0       0        0   \n",
      "2          0          0           0  ...        0          0       0        0   \n",
      "3          0          0           0  ...        0          0       0        0   \n",
      "4          0          0           0  ...        0          0       0        0   \n",
      "\n",
      "   Mystery  Romance  Sci-Fi  Thriller  War  Western  \n",
      "0        0        0       0         0    0        0  \n",
      "1        0        0       0         1    0        0  \n",
      "2        0        0       0         1    0        0  \n",
      "3        0        0       0         0    0        0  \n",
      "4        0        0       0         1    0        0  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "i_cols = [\n",
    "    'item_id', 'title', 'release_date', 'video_release_date', 'IMDb_URL',\n",
    "    'unknown', 'Action', 'Adventure', 'Animation', 'Children\\'s', 'Comedy',\n",
    "    'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror',\n",
    "    'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western'\n",
    "]\n",
    "\n",
    "movies_df = pd.read_csv(f'{data_folder}u.item', sep='|', names=i_cols, encoding='latin-1')\n",
    "\n",
    "print(\"\\nMovie Data Head:\")\n",
    "print(movies_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "102d0b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User Data Head:\n",
      "   user_id  age gender  occupation zip_code\n",
      "0        1   24      M  technician    85711\n",
      "1        2   53      F       other    94043\n",
      "2        3   23      M      writer    32067\n",
      "3        4   24      M  technician    43537\n",
      "4        5   33      F       other    15213\n"
     ]
    }
   ],
   "source": [
    "u_cols = ['user_id', 'age', 'gender', 'occupation', 'zip_code']\n",
    "\n",
    "users_df = pd.read_csv(f'{data_folder}u.user', sep='|', names=u_cols, encoding='latin-1')\n",
    "\n",
    "# Display the first few rows of the user data\n",
    "print(\"\\nUser Data Head:\")\n",
    "print(users_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671230b7",
   "metadata": {},
   "source": [
    "## Estructuras para métricas\n",
    "\n",
    "Para calcular las métricas, necesitamos saber, por ejemplo, el `ground truth` o la popularidad de los items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5933e90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupamos el DataFrame de test por usuario y convertimos los item_id de cada grupo en un conjunto (set)\n",
    "ground_truth = test_df[test_df['rating'] > 4].groupby('user_id')['item_id'].apply(set).to_dict()\n",
    "\n",
    "k_values = [10, 20, 50]\n",
    "\n",
    "# Contamos popularidad como suma de ratings para dar más peso a los items mejor puntuados\n",
    "item_popularity = train_df.groupby('item_id')['rating'].sum().to_dict()\n",
    "\n",
    "# Creamos el diccionario iterando sobre el dataframe de películas\n",
    "item_features = {}\n",
    "for index, row in movies_df.iterrows():\n",
    "    item_id = row['item_id']\n",
    "    # Creamos un conjunto con los nombres de las columnas de género donde el valor es 1\n",
    "    genres = {genre for genre in i_cols if row[genre] == 1}\n",
    "    item_features[item_id] = genres\n",
    "\n",
    "all_items = set(movies_df['item_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9678c8",
   "metadata": {},
   "source": [
    "## Random model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7e832b",
   "metadata": {},
   "source": [
    "Generaremos, para cada usuario, aleatoriamente una lista de hasta 50 recomendaciones para poder evaluar las métricas a distintos puntos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8e2e44de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener todos los IDs de películas únicos\n",
    "all_movie_ids = movies_df['item_id'].unique().tolist()\n",
    "\n",
    "# Crear el diccionario de ítems vistos por usuario (SOLO con datos de entrenamiento)\n",
    "user_seen_items = train_df.groupby('user_id')['item_id'].apply(set).to_dict()\n",
    "\n",
    "# Obtener la lista de usuarios para los que generaremos recomendaciones\n",
    "users_in_train = train_df['user_id'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "efbb53ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de películas: 1682\n",
      "Total de usuarios en el set de entrenamiento: 943\n",
      "Películas vistas por el usuario 1: {1, 2, 3, 4, 5, 7, 8, 9, 11, 13, 15, 16, 18, 19, 21, 22, 25, 26, 28, 29, 30, 32, 34, 35, 37, 38, 40, 41, 42, 43, 45, 46, 48, 50, 52, 55, 57, 58, 59, 63, 66, 68, 71, 75, 77, 79, 83, 87, 88, 89, 93, 94, 95, 99, 101, 105, 106, 109, 110, 111, 115, 116, 119, 122, 123, 124, 126, 127, 131, 133, 135, 136, 137, 138, 139, 141, 142, 144, 146, 147, 149, 152, 153, 156, 158, 162, 165, 166, 167, 168, 169, 172, 173, 176, 178, 179, 181, 182, 187, 191, 192, 194, 195, 197, 198, 199, 203, 204, 205, 207, 211, 216, 217, 220, 223, 231, 234, 237, 238, 239, 240, 244, 245, 246, 247, 249, 251, 256, 257, 261, 263, 268, 269, 270, 271}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total de películas: {len(all_movie_ids)}\")\n",
    "print(f\"Total de usuarios en el set de entrenamiento: {len(users_in_train)}\")\n",
    "print(f\"Películas vistas por el usuario 1: {user_seen_items[1]}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "42db2de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000 20000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df), len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "097a9e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_recommendations(users_to_recommend, all_movie_ids, user_seen_items, max_recommendations=50, random_state=42):\n",
    "    \"\"\"\n",
    "    Genera recomendaciones aleatorias para una lista de usuarios,\n",
    "    asegurándose de no recomendar ítems que ya han visto.\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    recommendations = {}\n",
    "    \n",
    "    for user_id in users_to_recommend:\n",
    "        # Obtener el conjunto de ítems que el usuario ya ha visto (del diccionario)\n",
    "        seen_items = user_seen_items.get(user_id, set())\n",
    "        \n",
    "        # Calcular los ítems candidatos (todos menos los ya vistos)\n",
    "        candidate_items = list(set(all_movie_ids) - seen_items)\n",
    "        \n",
    "        # Determinar cuántas recomendaciones generar\n",
    "        n_recommendations = min(max_recommendations, len(candidate_items))\n",
    "        \n",
    "        # Si hay candidatos, seleccionar aleatoriamente\n",
    "        if n_recommendations > 0:\n",
    "            recommended_items = np.random.choice(candidate_items, size=n_recommendations, replace=False).tolist()\n",
    "            recommendations[user_id] = recommended_items\n",
    "        else:\n",
    "            # En el caso improbable de que un usuario haya visto todo\n",
    "            recommendations[user_id] = []\n",
    "            \n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f7d3a74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_recs = generate_random_recommendations(\n",
    "    users_to_recommend=users_in_train,\n",
    "    all_movie_ids=all_movie_ids,\n",
    "    user_seen_items=user_seen_items,\n",
    "    max_recommendations=50, # Generar hasta 50 recomendaciones por usuario\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a55a9f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RECOMMENDATION EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "CATALOG COVERAGE:\n",
      "  @10: 0.9970\n",
      "  @20: 1.0000\n",
      "  @50: 1.0000\n",
      "\n",
      "F1:\n",
      "  @10: 0.0057\n",
      "  @20: 0.0069\n",
      "  @50: 0.0097\n",
      "\n",
      "INTRA LIST SIMILARITY:\n",
      "  @10: 0.1807\n",
      "  @20: 0.1807\n",
      "  @50: 0.1820\n",
      "\n",
      "MAP:\n",
      "  @10: 0.0020\n",
      "  @20: 0.0017\n",
      "  @50: 0.0023\n",
      "\n",
      "MRR:\n",
      "  @10: 0.0171\n",
      "  @20: 0.0204\n",
      "  @50: 0.0240\n",
      "\n",
      "NDCG:\n",
      "  @10: 0.4288\n",
      "  @20: 0.3621\n",
      "  @50: 0.2803\n",
      "\n",
      "NOVELTY:\n",
      "  @10: 12.4810\n",
      "  @20: 12.4729\n",
      "  @50: 12.4791\n",
      "\n",
      "PRECISION:\n",
      "  @10: 0.0069\n",
      "  @20: 0.0062\n",
      "  @50: 0.0060\n",
      "\n",
      "RECALL:\n",
      "  @10: 0.0048\n",
      "  @20: 0.0078\n",
      "  @50: 0.0247\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Run evaluation\n",
    "results = evaluate_recommendations(\n",
    "    recommendations=random_recs,\n",
    "    ground_truth=ground_truth,\n",
    "    k_values=k_values,\n",
    "    item_popularity=item_popularity,\n",
    "    all_items=all_items,\n",
    "    item_features=item_features\n",
    ")\n",
    "\n",
    "print_evaluation_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f0683f",
   "metadata": {},
   "source": [
    "## Most popular items\n",
    "\n",
    "En este caso, todas las recomendaciones seran iguales para todos los usuarios: recomendaremos las 50 películas más populares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ea8acf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agarramos el diccionario de popularidad y sacamos las 50 peliculas mas populares\n",
    "most_popular_items = sorted(item_popularity, key=item_popularity.get, reverse=True)\n",
    "most_popular_items = most_popular_items[:50]\n",
    "\n",
    "# Ahora llenamos las recomendaciones con las mismas peliculas para todos los usuarios\n",
    "pop_recs = {user_id: most_popular_items for user_id in users_in_train}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b3587d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RECOMMENDATION EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "CATALOG COVERAGE:\n",
      "  @10: 0.0059\n",
      "  @20: 0.0119\n",
      "  @50: 0.0297\n",
      "\n",
      "F1:\n",
      "  @10: 0.0882\n",
      "  @20: 0.1005\n",
      "  @50: 0.0978\n",
      "\n",
      "INTRA LIST SIMILARITY:\n",
      "  @10: 0.1497\n",
      "  @20: 0.1935\n",
      "  @50: 0.1776\n",
      "\n",
      "MAP:\n",
      "  @10: 0.0548\n",
      "  @20: 0.0562\n",
      "  @50: 0.0660\n",
      "\n",
      "MRR:\n",
      "  @10: 0.2258\n",
      "  @20: 0.2377\n",
      "  @50: 0.2420\n",
      "\n",
      "NDCG:\n",
      "  @10: 0.5616\n",
      "  @20: 0.4781\n",
      "  @50: 0.4241\n",
      "\n",
      "NOVELTY:\n",
      "  @10: 7.5304\n",
      "  @20: 7.7083\n",
      "  @50: 8.0123\n",
      "\n",
      "PRECISION:\n",
      "  @10: 0.0770\n",
      "  @20: 0.0698\n",
      "  @50: 0.0578\n",
      "\n",
      "RECALL:\n",
      "  @10: 0.1032\n",
      "  @20: 0.1793\n",
      "  @50: 0.3175\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Run evaluation\n",
    "results = evaluate_recommendations(\n",
    "    recommendations=pop_recs,\n",
    "    ground_truth=ground_truth,\n",
    "    k_values=k_values,\n",
    "    item_popularity=item_popularity,\n",
    "    all_items=all_items,\n",
    "    item_features=item_features\n",
    ")\n",
    "\n",
    "print_evaluation_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5ce1c2",
   "metadata": {},
   "source": [
    "## User-based KNN\n",
    "\n",
    "Como modelo informado base, escogemos el user-based KNN. Partiendo siempre desde la hipotesis de que tenemos ya bastentes datos de nuestros usuarios y ahora nuestro objetivo es recomendarles películas relevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f78c1277",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_str = train_df.copy()\n",
    "train_df_str['user_id'] = train_df_str['user_id'].astype(str)\n",
    "train_df_str['item_id'] = train_df_str['item_id'].astype(str)\n",
    "\n",
    "test_df_str = test_df.copy()\n",
    "test_df_str['user_id'] = test_df_str['user_id'].astype(str)\n",
    "test_df_str['item_id'] = test_df_str['item_id'].astype(str)\n",
    "\n",
    "trainset = [tuple(row) for row in train_df_str[['user_id', 'item_id', 'rating']].values]\n",
    "testset = [tuple(row) for row in test_df_str[['user_id', 'item_id', 'rating']].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c259bd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "myUserKnn = UserKNN(k=7, similarity='cosine')\n",
    "myUserKnn.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "796d768b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item 599 unknown, returning user mean.\n",
      "Item 711 unknown, returning user mean.\n",
      "Item 814 unknown, returning user mean.\n",
      "Item 830 unknown, returning user mean.\n",
      "Item 852 unknown, returning user mean.\n",
      "Item 857 unknown, returning user mean.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item 1156 unknown, returning user mean.\n",
      "Item 1236 unknown, returning user mean.\n",
      "Item 1309 unknown, returning user mean.\n",
      "Item 1310 unknown, returning user mean.\n",
      "Item 1320 unknown, returning user mean.\n",
      "Item 1343 unknown, returning user mean.\n",
      "Item 1348 unknown, returning user mean.\n",
      "Item 1364 unknown, returning user mean.\n",
      "Item 1373 unknown, returning user mean.\n",
      "Item 1457 unknown, returning user mean.\n",
      "Item 1458 unknown, returning user mean.\n",
      "Item 1492 unknown, returning user mean.\n",
      "Item 1493 unknown, returning user mean.\n",
      "Item 1498 unknown, returning user mean.\n",
      "Item 1505 unknown, returning user mean.\n",
      "Item 1520 unknown, returning user mean.\n",
      "Item 1533 unknown, returning user mean.\n",
      "Item 1536 unknown, returning user mean.\n",
      "Item 1543 unknown, returning user mean.\n",
      "Item 1557 unknown, returning user mean.\n",
      "Item 1561 unknown, returning user mean.\n",
      "Item 1562 unknown, returning user mean.\n",
      "Item 1563 unknown, returning user mean.\n",
      "Item 1565 unknown, returning user mean.\n",
      "Item 1582 unknown, returning user mean.\n",
      "Item 1586 unknown, returning user mean.\n",
      "RMSE: 0.9808, MAE: 0.7655\n"
     ]
    }
   ],
   "source": [
    "# Predicciones para todo el testset\n",
    "predictions = myUserKnn.predict_all(testset)\n",
    "rmse = calculate_rmse(predictions)\n",
    "mae = calculate_mae(predictions)\n",
    "print(f\"RMSE: {rmse:.4f}, MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32efe72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_in_train = train_df['user_id'].astype(str).unique().tolist()\n",
    "top_n_all = myUserKnn.get_top_n(user_ids=users_in_train, n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbbf597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir top_n al formato correcto (solo item_ids) y keys a int\n",
    "uknn_recs = {\n",
    "    int(uid): [int(item_id) for item_id, _ in items]\n",
    "    for uid, items in top_n_all.items()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae20dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RECOMMENDATION EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "CATALOG COVERAGE:\n",
      "  @10: 0.1367\n",
      "  @20: 0.2111\n",
      "  @50: 0.3502\n",
      "\n",
      "F1:\n",
      "  @10: 0.0180\n",
      "  @20: 0.0303\n",
      "  @50: 0.0710\n",
      "\n",
      "INTRA LIST SIMILARITY:\n",
      "  @10: 0.3709\n",
      "  @20: 0.3400\n",
      "  @50: 0.2392\n",
      "\n",
      "MAP:\n",
      "  @10: 0.0158\n",
      "  @20: 0.0126\n",
      "  @50: 0.0142\n",
      "\n",
      "MRR:\n",
      "  @10: 0.1080\n",
      "  @20: 0.1198\n",
      "  @50: 0.1300\n",
      "\n",
      "NDCG:\n",
      "  @10: 0.5182\n",
      "  @20: 0.4280\n",
      "  @50: 0.3553\n",
      "\n",
      "NOVELTY:\n",
      "  @10: 13.2394\n",
      "  @20: 13.1858\n",
      "  @50: 12.2810\n",
      "\n",
      "PRECISION:\n",
      "  @10: 0.0410\n",
      "  @20: 0.0442\n",
      "  @50: 0.0608\n",
      "\n",
      "RECALL:\n",
      "  @10: 0.0115\n",
      "  @20: 0.0231\n",
      "  @50: 0.0853\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_recommendations(\n",
    "    recommendations=uknn_recs,\n",
    "    ground_truth=ground_truth,\n",
    "    k_values=k_values,\n",
    "    item_popularity=item_popularity,\n",
    "    all_items=all_items,\n",
    "    item_features=item_features\n",
    ")\n",
    "\n",
    "print_evaluation_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386057c3",
   "metadata": {},
   "source": [
    "## DeepFM\n",
    "\n",
    "Como modelo híbrido, utilizamos DeepFM, que combina Factorization Machines (FM) y Deep Neural Networks (DNN). El componente FM capta interacciones simples entre usuarios e ítems, mientras que el DNN aprende patrones complejos y no lineales. Gracias a los embeddings compartidos, DeepFM modela ambos niveles (patrones simples y complejos) asi evitando sobreajuste para un dataset como el nuestro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119d29f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.DeepFM import DeepFM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc93dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepfm_model = DeepFM(\n",
    "    embedding_dim=16,\n",
    "    dnn_hidden_units=(128, 64),\n",
    "    dnn_dropout=0.2,\n",
    "    learning_rate=0.001,\n",
    "    epochs=10,\n",
    "    batch_size=2048,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a053bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Train on 80000 samples, validate on 19968 samples, 40 steps per epoch\n",
      "Epoch 1/10\n",
      "1s - loss:  0.6845 - auc:  0.6259 - val_auc:  0.7576\n",
      "Epoch 2/10\n",
      "0s - loss:  0.6461 - auc:  0.7674 - val_auc:  0.7630\n",
      "Epoch 3/10\n",
      "0s - loss:  0.5911 - auc:  0.7794 - val_auc:  0.7706\n",
      "Epoch 4/10\n",
      "0s - loss:  0.5702 - auc:  0.7894 - val_auc:  0.7742\n",
      "Epoch 5/10\n",
      "0s - loss:  0.5589 - auc:  0.7934 - val_auc:  0.7750\n",
      "Epoch 6/10\n",
      "0s - loss:  0.5524 - auc:  0.7945 - val_auc:  0.7767\n",
      "Epoch 7/10\n",
      "1s - loss:  0.5484 - auc:  0.7968 - val_auc:  0.7772\n",
      "Epoch 8/10\n",
      "1s - loss:  0.5459 - auc:  0.7979 - val_auc:  0.7773\n",
      "Epoch 9/10\n",
      "1s - loss:  0.5441 - auc:  0.7979 - val_auc:  0.7779\n",
      "Epoch 10/10\n",
      "0s - loss:  0.5425 - auc:  0.7964 - val_auc:  0.7791\n"
     ]
    }
   ],
   "source": [
    "# Filtrar test_df para solo incluir items que están en train\n",
    "train_items = set(train_df['item_id'].unique())\n",
    "test_df_filtered = test_df[test_df['item_id'].isin(train_items)].copy()\n",
    "\n",
    "history = deepfm_model.fit(train_df, val_df=test_df_filtered)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b38817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir user_ids a string para consistencia\n",
    "users_for_deepfm = train_df['user_id'].astype(str).unique().tolist()\n",
    "\n",
    "# Crear DataFrame de test con todas las combinaciones user-item no vistas\n",
    "user_seen_items_int = train_df.groupby('user_id')['item_id'].apply(set).to_dict()\n",
    "all_items_list = train_df['item_id'].unique().tolist()\n",
    "\n",
    "test_pairs = []\n",
    "for user_id in train_df['user_id'].unique():\n",
    "    seen = user_seen_items_int.get(user_id, set())\n",
    "    unseen = [item for item in all_items_list if item not in seen]\n",
    "    for item_id in unseen:\n",
    "        test_pairs.append({'user_id': user_id, 'item_id': item_id, 'rating': 0})\n",
    "\n",
    "test_for_pred = pd.DataFrame(test_pairs)\n",
    "\n",
    "# Obtener top-N recomendaciones\n",
    "deepfm_top_n = deepfm_model.get_top_n(test_for_pred, n=50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377bb048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir keys a int\n",
    "deepfm_recs = {\n",
    "    int(uid): items\n",
    "    for uid, items in deepfm_recs.items()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fbdf6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RECOMMENDATION EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "CATALOG COVERAGE:\n",
      "  @10: 0.0161\n",
      "  @20: 0.0297\n",
      "  @50: 0.0672\n",
      "\n",
      "F1:\n",
      "  @10: 0.0234\n",
      "  @20: 0.0473\n",
      "  @50: 0.0748\n",
      "\n",
      "INTRA LIST SIMILARITY:\n",
      "  @10: 0.2713\n",
      "  @20: 0.2677\n",
      "  @50: 0.2192\n",
      "\n",
      "MAP:\n",
      "  @10: 0.0142\n",
      "  @20: 0.0162\n",
      "  @50: 0.0149\n",
      "\n",
      "MRR:\n",
      "  @10: 0.0659\n",
      "  @20: 0.0776\n",
      "  @50: 0.0858\n",
      "\n",
      "NDCG:\n",
      "  @10: 0.4088\n",
      "  @20: 0.3864\n",
      "  @50: 0.3432\n",
      "\n",
      "NOVELTY:\n",
      "  @10: 11.0536\n",
      "  @20: 10.7322\n",
      "  @50: 11.1388\n",
      "\n",
      "PRECISION:\n",
      "  @10: 0.0566\n",
      "  @20: 0.0696\n",
      "  @50: 0.0617\n",
      "\n",
      "RECALL:\n",
      "  @10: 0.0147\n",
      "  @20: 0.0358\n",
      "  @50: 0.0950\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "results_deepfm = evaluate_recommendations(\n",
    "    recommendations=deepfm_recs,\n",
    "    ground_truth=ground_truth,\n",
    "    k_values=k_values,\n",
    "    item_popularity=item_popularity,\n",
    "    all_items=all_items,\n",
    "    item_features=item_features\n",
    ")\n",
    "\n",
    "print_evaluation_results(results_deepfm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7e92bb",
   "metadata": {},
   "source": [
    "\n",
    "## Ensamble híbrido\n",
    "\n",
    "Implementamos un ensemble híbrido que combina las predicciones de User-KNN y DeepFM mediante ponderación. User-KNN aporta interpretabilidad y diversidad, mientras que DeepFM ofrece precisión al capturar interacciones no lineales. Con un peso 70/30 se buscaun equilibrio entre cobertura y exactitud, esperando un buen rendimiento individual de cada modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46be1056",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ensemble import HybridEnsemble\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6f5ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-KNN ya tiene scores en top_n_all\n",
    "uknn_with_scores = {\n",
    "    int(uid): [(int(item_id), score) for item_id, score in items]\n",
    "    for uid, items in top_n_all.items()\n",
    "}\n",
    "\n",
    "# DeepFM también tiene scores en deepfm_top_n\n",
    "deepfm_with_scores = {\n",
    "    int(uid): [(int(float(item_id)), score) for item_id, score in items]\n",
    "    for uid, items in deepfm_top_n.items()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e004f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ENSEMBLE WEIGHTED (70% DeepFM, 30% User-KNN) ===\n",
      "\n",
      "============================================================\n",
      "RECOMMENDATION EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "CATALOG COVERAGE:\n",
      "  @10: 0.0404\n",
      "  @20: 0.1439\n",
      "  @50: 0.3502\n",
      "\n",
      "F1:\n",
      "  @10: 0.0287\n",
      "  @20: 0.0532\n",
      "  @50: 0.0710\n",
      "\n",
      "INTRA LIST SIMILARITY:\n",
      "  @10: 0.2868\n",
      "  @20: 0.2693\n",
      "  @50: 0.2392\n",
      "\n",
      "MAP:\n",
      "  @10: 0.0177\n",
      "  @20: 0.0173\n",
      "  @50: 0.0153\n",
      "\n",
      "MRR:\n",
      "  @10: 0.1045\n",
      "  @20: 0.1196\n",
      "  @50: 0.1238\n",
      "\n",
      "NDCG:\n",
      "  @10: 0.4332\n",
      "  @20: 0.3909\n",
      "  @50: 0.3689\n",
      "\n",
      "NOVELTY:\n",
      "  @10: 11.7159\n",
      "  @20: 11.6239\n",
      "  @50: 12.2810\n",
      "\n",
      "PRECISION:\n",
      "  @10: 0.0638\n",
      "  @20: 0.0708\n",
      "  @50: 0.0608\n",
      "\n",
      "RECALL:\n",
      "  @10: 0.0185\n",
      "  @20: 0.0426\n",
      "  @50: 0.0853\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "ensemble_weighted = HybridEnsemble(strategy='weighted', weights=[0.7, 0.3])\n",
    "weighted_recs = ensemble_weighted.combine(deepfm_with_scores, uknn_with_scores, n=50)\n",
    "\n",
    "results_weighted = evaluate_recommendations(\n",
    "    recommendations=weighted_recs,\n",
    "    ground_truth=ground_truth,\n",
    "    k_values=k_values,\n",
    "    item_popularity=item_popularity,\n",
    "    all_items=all_items,\n",
    "    item_features=item_features\n",
    ")\n",
    "\n",
    "print(\"=== ENSEMBLE WEIGHTED (70% DeepFM, 30% User-KNN) ===\")\n",
    "print_evaluation_results(results_weighted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545ed984",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
