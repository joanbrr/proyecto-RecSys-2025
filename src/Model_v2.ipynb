{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "957264fe",
      "metadata": {
        "id": "957264fe"
      },
      "source": [
        "# Knowledge-Aware Recommender V2 (PyTorch Geometric Version)\n",
        "\n",
        "**Architecture:**\n",
        "1.  **Deep & Wide:** Embedding dimensions (256/512).\n",
        "2.  **Rating-Aware Attention:** Custom PyG MessagePassing layer that attends to neighbors + edge ratings.\n",
        "3.  **Complementary Fusion:** Graph + Text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb056f2e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb056f2e",
        "outputId": "9aefc23c-af48-423b-e852-05b4230d558d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from collections import defaultdict\n",
        "from recomender_metrics import evaluate_recommendations, print_evaluation_results\n",
        "from torch_geometric.data import HeteroData\n",
        "from torch_geometric.nn import MessagePassing\n",
        "from torch_geometric.utils import softmax\n",
        "\n",
        "# Check for GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Configuration\n",
        "EMBED_DIM = 128\n",
        "HIDDEN_DIM = 256\n",
        "ATTENTION_HEADS = 4\n",
        "DROPOUT = 0.3\n",
        "LR = 0.001\n",
        "EPOCHS = 15\n",
        "BATCH_SIZE = 512 # Can increase batch size now that model is lighter\n",
        "TEXT_EMBED_PATH = 'movie_text_embeddings.pt'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d9e62cd",
      "metadata": {
        "id": "2d9e62cd"
      },
      "source": [
        "## 1. Data Loading: Building HeteroData (PyG)\n",
        "PyG stores graphs in a `HeteroData` object.\n",
        "Edge indices are tensors of shape `[2, num_edges]`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "730763f1",
      "metadata": {
        "id": "730763f1"
      },
      "outputs": [],
      "source": [
        "def load_data_and_build_graph():\n",
        "    print(\"Loading datasets...\")\n",
        "\n",
        "    movies_df = pd.read_csv('movies_graph_ready.csv')\n",
        "    train_df = pd.read_csv('ml-100k/u1.base', sep='\\t', names=['user_id', 'movie_id', 'rating', 'timestamp'])\n",
        "    test_df = pd.read_csv('ml-100k/u1.test', sep='\\t', names=['user_id', 'movie_id', 'rating', 'timestamp'])\n",
        "\n",
        "    nodes_dir = 'nodes'\n",
        "    genres_df = pd.read_csv(f'{nodes_dir}/genres.csv')\n",
        "    keywords_df = pd.read_csv(f'{nodes_dir}/keywords.csv')\n",
        "    directors_df = pd.read_csv(f'{nodes_dir}/directors.csv')\n",
        "    writers_df = pd.read_csv(f'{nodes_dir}/writers.csv')\n",
        "\n",
        "    # --- ID MAPPING ---\n",
        "    all_users = pd.concat([train_df['user_id'], test_df['user_id']]).unique()\n",
        "    all_movies = movies_df['ml_movie_id'].unique()\n",
        "\n",
        "    user_map = {uid: i for i, uid in enumerate(all_users)}\n",
        "    movie_map = {mid: i for i, mid in enumerate(all_movies)}\n",
        "\n",
        "    # Reverse mappings\n",
        "    id_to_user = {v: k for k, v in user_map.items()}\n",
        "    id_to_movie = {v: k for k, v in movie_map.items()}\n",
        "\n",
        "    # Aux nodes maps\n",
        "    genre_map = {gid: i for i, gid in enumerate(genres_df['id'])}\n",
        "    keyword_map = {kid: i for i, kid in enumerate(keywords_df['id'])}\n",
        "    director_map = {did: i for i, did in enumerate(directors_df['id'])}\n",
        "    writer_map = {wid: i for i, wid in enumerate(writers_df['id'])}\n",
        "\n",
        "    # --- GRAPH CONSTRUCTION (PyG HeteroData) ---\n",
        "    data = HeteroData()\n",
        "\n",
        "    # Set Number of Nodes (Important for PyG)\n",
        "    data['user'].num_nodes = len(user_map)\n",
        "    data['movie'].num_nodes = len(movie_map)\n",
        "    data['genre'].num_nodes = len(genre_map)\n",
        "    data['keyword'].num_nodes = len(keyword_map)\n",
        "    data['director'].num_nodes = len(director_map)\n",
        "    data['writer'].num_nodes = len(writer_map)\n",
        "\n",
        "    # User-Movie Edges (ALL RATINGS)\n",
        "    u_list, m_list, r_list = [], [], []\n",
        "\n",
        "    valid_u = set(user_map.keys())\n",
        "    valid_m = set(movie_map.keys())\n",
        "\n",
        "    print(\"Building User-Movie edges with Ratings...\")\n",
        "    for u, m, r in zip(train_df['user_id'], train_df['movie_id'], train_df['rating']):\n",
        "        if u in valid_u and m in valid_m:\n",
        "            u_list.append(user_map[u])\n",
        "            m_list.append(movie_map[m])\n",
        "            r_list.append(r - 1) # 0-4 index\n",
        "\n",
        "    # PyG expects edge_index as [2, Num_Edges]\n",
        "    rates_index = torch.tensor([u_list, m_list], dtype=torch.long)\n",
        "    rated_by_index = torch.tensor([m_list, u_list], dtype=torch.long)\n",
        "    ratings = torch.tensor(r_list, dtype=torch.long)\n",
        "\n",
        "    data['user', 'rates', 'movie'].edge_index = rates_index\n",
        "    data['user', 'rates', 'movie'].rating = ratings\n",
        "\n",
        "    data['movie', 'rated_by', 'user'].edge_index = rated_by_index\n",
        "    data['movie', 'rated_by', 'user'].rating = ratings # Symmetric rating info\n",
        "\n",
        "    # Metadata Edges\n",
        "    def build_attr_edges(df, col_name, map_dict, target_ntype, edge_name):\n",
        "        src, dst = [], []\n",
        "        for _, row in df.iterrows():\n",
        "            if row['ml_movie_id'] not in movie_map: continue\n",
        "            mid = movie_map[row['ml_movie_id']]\n",
        "            try:\n",
        "                ids = json.loads(row[col_name])\n",
        "                if isinstance(ids, list):\n",
        "                    for x in ids:\n",
        "                        if x in map_dict:\n",
        "                            src.append(mid); dst.append(map_dict[x])\n",
        "            except: continue\n",
        "\n",
        "        if len(src) > 0:\n",
        "            edge_index = torch.tensor([src, dst], dtype=torch.long)\n",
        "            rev_edge_index = torch.tensor([dst, src], dtype=torch.long)\n",
        "\n",
        "            data['movie', f'has_{edge_name}', target_ntype].edge_index = edge_index\n",
        "            data[target_ntype, f'{edge_name}_of', 'movie'].edge_index = rev_edge_index\n",
        "\n",
        "    build_attr_edges(movies_df, 'genres', genre_map, 'genre', 'genre')\n",
        "    build_attr_edges(movies_df, 'keywords', keyword_map, 'keyword', 'keyword')\n",
        "    build_attr_edges(movies_df, 'directors', director_map, 'director', 'director')\n",
        "    build_attr_edges(movies_df, 'writers', writer_map, 'writer', 'writer')\n",
        "\n",
        "    # --- EVALUATION METADATA ---\n",
        "    movie_genres_dict = {}\n",
        "    id_to_genre_name = dict(zip(genres_df['id'], genres_df['name']))\n",
        "\n",
        "    for _, row in movies_df.iterrows():\n",
        "        mid = str(row['ml_movie_id'])\n",
        "        try:\n",
        "            g_ids = json.loads(row['genres'])\n",
        "            names = {id_to_genre_name.get(gid, 'unknown') for gid in g_ids}\n",
        "            movie_genres_dict[mid] = names\n",
        "        except:\n",
        "            movie_genres_dict[mid] = set()\n",
        "\n",
        "    mappings = {\n",
        "        'user_map': user_map, 'movie_map': movie_map,\n",
        "        'id_to_user': id_to_user, 'id_to_movie': id_to_movie,\n",
        "        'movie_genres': movie_genres_dict\n",
        "    }\n",
        "\n",
        "    return data, mappings, train_df, test_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbd0cd93",
      "metadata": {
        "id": "fbd0cd93"
      },
      "source": [
        "## 2. Custom PyG Graph Layer\n",
        "We implement `RatingAwareGAT` by inheriting from `MessagePassing`.\n",
        "This requires handling the heterogeneity manually or via wrapper. Here we use a ModuleDict to handle different relation types explicitly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1046dc74",
      "metadata": {
        "id": "1046dc74"
      },
      "outputs": [],
      "source": [
        "class SingleRelationGAT(MessagePassing):\n",
        "    \"\"\"\n",
        "    Performs the attention mechanism for ONE specific edge type (e.g., User->Movie).\n",
        "    Supports optional edge rating features.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_feat, out_feat, num_heads, feat_drop, has_rating=False):\n",
        "        super().__init__(node_dim=0, aggr='add') # Target node aggregation is sum\n",
        "        self.out_feat = out_feat\n",
        "        self.num_heads = num_heads\n",
        "        self.has_rating = has_rating\n",
        "\n",
        "        # Transformation W\n",
        "        self.W = nn.Linear(in_feat, out_feat * num_heads, bias=False)\n",
        "\n",
        "        # Attention Vectors\n",
        "        self.attn_l = nn.Parameter(torch.randn(1, num_heads, out_feat))\n",
        "        self.attn_r = nn.Parameter(torch.randn(1, num_heads, out_feat))\n",
        "\n",
        "        if has_rating:\n",
        "            # 5 ratings -> mapped to attention space\n",
        "            self.rating_embedding = nn.Embedding(5, out_feat * num_heads)\n",
        "            self.attn_rating = nn.Parameter(torch.randn(1, num_heads, out_feat))\n",
        "\n",
        "        self.feat_drop = nn.Dropout(feat_drop)\n",
        "        self.leaky_relu = nn.LeakyReLU(0.2)\n",
        "\n",
        "        nn.init.xavier_uniform_(self.W.weight)\n",
        "        nn.init.xavier_uniform_(self.attn_l)\n",
        "        nn.init.xavier_uniform_(self.attn_r)\n",
        "\n",
        "    def forward(self, x_src, x_dst, edge_index, rel_emb, edge_rating=None):\n",
        "        # x_src: [N_src, In]\n",
        "        # rel_emb: [In] -> Broadcast to [N_src, In]\n",
        "\n",
        "        # Transform Source (Add Relation Embedding first)\n",
        "        # We pass (x_src + rel) to the message function to project it there\n",
        "        # Or project here for efficiency.\n",
        "\n",
        "        # Project Source\n",
        "        h_src = self.W(x_src + rel_emb).view(-1, self.num_heads, self.out_feat)\n",
        "        # Project Dest\n",
        "        h_dst = self.W(x_dst).view(-1, self.num_heads, self.out_feat)\n",
        "\n",
        "        # Pre-calculate Attention Terms (Optimization)\n",
        "        # alpha_l = (W(h+r) * a_l).sum\n",
        "        alpha_l = (h_src * self.attn_l).sum(dim=-1) # [N_src, Heads]\n",
        "        alpha_r = (h_dst * self.attn_r).sum(dim=-1) # [N_dst, Heads]\n",
        "\n",
        "        # Propagate\n",
        "        # Flow: Source -> Target\n",
        "        out = self.propagate(edge_index, x=(h_src, h_dst), alpha=(alpha_l, alpha_r), edge_rating=edge_rating)\n",
        "\n",
        "        # Final transformation (Mean over heads + Activation)\n",
        "        out = out.mean(dim=1) # [N_dst, Out]\n",
        "        return self.leaky_relu(out)\n",
        "\n",
        "    def message(self, x_j, alpha_j, alpha_i, index, ptr, size_i, edge_rating):\n",
        "        # x_j: Source Node Features (Projected) [E, Heads, Out]\n",
        "        # alpha_j: Source Attention Term [E, Heads]\n",
        "        # alpha_i: Target Attention Term [E, Heads]\n",
        "        # index: The indices of destination nodes (for softmax)\n",
        "\n",
        "        # Base Attention Score\n",
        "        score = alpha_j + alpha_i\n",
        "\n",
        "        # Add Rating Info if available\n",
        "        if self.has_rating and edge_rating is not None:\n",
        "            # Embed Rating: [E] -> [E, Heads*Out] -> [E, Heads, Out]\n",
        "            r_emb = self.rating_embedding(edge_rating).view(-1, self.num_heads, self.out_feat)\n",
        "            # Attention contribution: (r_emb * attn_vec).sum\n",
        "            r_score = (r_emb * self.attn_rating).sum(dim=-1) # [E, Heads]\n",
        "            score = score + r_score\n",
        "\n",
        "        score = F.leaky_relu(score, 0.2)\n",
        "\n",
        "        # Softmax over neighbors\n",
        "        alpha = softmax(score, index, ptr, size_i) # [E, Heads]\n",
        "        alpha = F.dropout(alpha, p=0.2, training=self.training)\n",
        "\n",
        "        # Weighted Sum\n",
        "        return x_j * alpha.unsqueeze(-1)\n",
        "\n",
        "class HeteroRatingGAT(nn.Module):\n",
        "    def __init__(self, data_metadata, in_feat, out_feat, num_heads, feat_drop=0.4):\n",
        "        super().__init__()\n",
        "        self.node_types, self.edge_types = data_metadata\n",
        "\n",
        "        # Learnable Relation Embeddings (Node-Level, unique per relation type)\n",
        "        self.rel_embeddings = nn.ParameterDict()\n",
        "        for src, rel, dst in self.edge_types:\n",
        "            self.rel_embeddings[f'{src}__{rel}__{dst}'] = nn.Parameter(torch.randn(in_feat))\n",
        "\n",
        "        # Create a GAT Layer for each edge type\n",
        "        self.convs = nn.ModuleDict()\n",
        "        for src, rel, dst in self.edge_types:\n",
        "            key = f'{src}__{rel}__{dst}'\n",
        "            # Only 'rates' and 'rated_by' have ratings\n",
        "            has_rating = (rel == 'rates' or rel == 'rated_by')\n",
        "            self.convs[key] = SingleRelationGAT(in_feat, out_feat, num_heads, feat_drop, has_rating)\n",
        "\n",
        "    def forward(self, x_dict, edge_index_dict, edge_attr_dict=None):\n",
        "        out_dict = defaultdict(list)\n",
        "\n",
        "        # Iterate over all edge types\n",
        "        for src, rel, dst in self.edge_types:\n",
        "            key = f'{src}__{rel}__{dst}'\n",
        "            edge_index = edge_index_dict[(src, rel, dst)]\n",
        "\n",
        "            # Skip if edge type empty\n",
        "            if edge_index.numel() == 0: continue\n",
        "\n",
        "            # Get inputs\n",
        "            x_src = x_dict[src]\n",
        "            x_dst = x_dict[dst]\n",
        "            rel_emb = self.rel_embeddings[key]\n",
        "\n",
        "            # Get ratings if available\n",
        "            ratings = None\n",
        "            if edge_attr_dict and (src, rel, dst) in edge_attr_dict:\n",
        "                ratings = edge_attr_dict[(src, rel, dst)]\n",
        "\n",
        "            # Compute Message Passing for this edge type\n",
        "            out = self.convs[key](x_src, x_dst, edge_index, rel_emb, ratings)\n",
        "            out_dict[dst].append(out)\n",
        "\n",
        "        # Aggregate results for each node type (Sum Aggregation)\n",
        "        final_out = {}\n",
        "        for ntype, outs in out_dict.items():\n",
        "            if len(outs) > 0:\n",
        "                final_out[ntype] = sum(outs)\n",
        "            else:\n",
        "                # Handle isolated nodes (just return zeros or original)\n",
        "                # Since we changed dimensions, we return zeros\n",
        "                final_out[ntype] = torch.zeros((x_dict[ntype].size(0), self.convs.values().__iter__().__next__().out_feat), device=x_dict[ntype].device)\n",
        "\n",
        "        return final_out"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a0ab297",
      "metadata": {
        "id": "4a0ab297"
      },
      "source": [
        "## 3. Text Module & Fusion (PyTorch)\n",
        "These remain largely standard PyTorch modules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2405f53e",
      "metadata": {
        "id": "2405f53e"
      },
      "outputs": [],
      "source": [
        "class DeepReviewAggregator(nn.Module):\n",
        "    def __init__(self, embed_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Linear(embed_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2)\n",
        "        )\n",
        "        self.query = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, review_embs, mask=None):\n",
        "        # review_embs: [B, M, Emb]\n",
        "        h = self.proj(review_embs) # [B, M, Hidden]\n",
        "        scores = self.query(h) # [B, M, 1]\n",
        "\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask.unsqueeze(-1) == 0, -1e9)\n",
        "        weights = F.softmax(scores, dim=1)\n",
        "\n",
        "        return (weights * h).sum(dim=1) # [B, Hidden]\n",
        "\n",
        "class GatedCrossAttention(nn.Module):\n",
        "    def __init__(self, dim, num_heads=4):\n",
        "        super().__init__()\n",
        "        self.mha = nn.MultiheadAttention(embed_dim=dim, num_heads=num_heads, batch_first=True)\n",
        "        self.gate = nn.Sequential(nn.Linear(dim * 2, dim), nn.Sigmoid())\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "\n",
        "    def forward(self, x_graph, x_text):\n",
        "        q = x_graph.unsqueeze(1)\n",
        "        k = v = x_text.unsqueeze(1)\n",
        "        attn_out, _ = self.mha(q, k, v)\n",
        "        attn_out = attn_out.squeeze(1)\n",
        "\n",
        "        concat = torch.cat([x_graph, attn_out], dim=-1)\n",
        "        alpha = self.gate(concat)\n",
        "        return self.norm(alpha * x_graph + (1 - alpha) * attn_out)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7a52401",
      "metadata": {
        "id": "a7a52401"
      },
      "source": [
        "## 4. Full Model Assembly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0ed1913",
      "metadata": {
        "id": "b0ed1913"
      },
      "outputs": [],
      "source": [
        "class RecommenderPyG(nn.Module):\n",
        "    def __init__(self, metadata, text_input_dim, hidden_dim, num_heads):\n",
        "        super().__init__()\n",
        "        node_types, _ = metadata\n",
        "\n",
        "        # Initial Node Embeddings\n",
        "        # PyG doesn't store embeddings in the graph object automatically like DGL\n",
        "        # We manage them here.\n",
        "        self.node_embeds = nn.ModuleDict()\n",
        "        # We need num_nodes. In PyG metadata doesn't strictly provide counts unless passed separately.\n",
        "        # We will initialize these dynamically or pass a dict.\n",
        "        # For now, we will assume `num_nodes_dict` is passed in `__init__` or handled externally.\n",
        "        # Updated init signature to accept `num_nodes_dict`\n",
        "        pass\n",
        "\n",
        "    def init_embeddings(self, num_nodes_dict, hidden_dim):\n",
        "        self.node_embeds = nn.ModuleDict()\n",
        "        for ntype, count in num_nodes_dict.items():\n",
        "            self.node_embeds[ntype] = nn.Embedding(count, hidden_dim)\n",
        "\n",
        "    def setup_layers(self, metadata, text_input_dim, hidden_dim, num_heads):\n",
        "        self.text_proj = nn.Sequential(nn.Linear(text_input_dim, hidden_dim), nn.ReLU())\n",
        "        self.gnn = HeteroRatingGAT(metadata, hidden_dim, hidden_dim, num_heads)\n",
        "        self.review_agg = DeepReviewAggregator(hidden_dim, hidden_dim)\n",
        "        self.fusion = GatedCrossAttention(hidden_dim, num_heads)\n",
        "        self.predict_layer = nn.Sequential(\n",
        "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(hidden_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x_dict, edge_index_dict, edge_attr_dict, users, items, ov, rev, mask):\n",
        "        # Get initial features from embeddings\n",
        "        # If x_dict contains indices, embed them.\n",
        "        h_dict = {ntype: self.node_embeds[ntype](x_dict[ntype]) for ntype in x_dict}\n",
        "\n",
        "        # Graph Pass\n",
        "        h_dict = self.gnn(h_dict, edge_index_dict, edge_attr_dict)\n",
        "        u_graph = h_dict['user'][users]\n",
        "        i_graph = h_dict['movie'][items]\n",
        "\n",
        "        # Text Pass\n",
        "        feat_ov = self.text_proj(ov)\n",
        "        feat_rev_raw = self.text_proj(rev)\n",
        "        agg_rev = self.review_agg(feat_rev_raw, mask)\n",
        "        i_text = (feat_ov + agg_rev) / 2\n",
        "\n",
        "        # Fusion\n",
        "        i_fused = self.fusion(i_graph, i_text)\n",
        "\n",
        "        # Predict\n",
        "        x = torch.cat([u_graph, i_fused], dim=-1)\n",
        "        return self.predict_layer(x)\n",
        "\n",
        "    def get_all_embeddings(self, x_dict, edge_index_dict, edge_attr_dict, ov, rev, mask):\n",
        "        with torch.no_grad():\n",
        "            h_dict = {ntype: self.node_embeds[ntype](x_dict[ntype]) for ntype in x_dict}\n",
        "            h_dict = self.gnn(h_dict, edge_index_dict, edge_attr_dict)\n",
        "\n",
        "            feat_ov = self.text_proj(ov)\n",
        "            feat_rev_raw = self.text_proj(rev)\n",
        "            agg_rev = self.review_agg(feat_rev_raw, mask)\n",
        "            i_text_all = (feat_ov + agg_rev) / 2\n",
        "\n",
        "            i_fused_all = self.fusion(h_dict['movie'], i_text_all)\n",
        "            return h_dict['user'], i_fused_all\n",
        "\n",
        "# Wrapper to instantiate properly\n",
        "def create_model(data, text_dim, hidden_dim, num_heads):\n",
        "    model = RecommenderPyG(data.metadata(), text_dim, hidden_dim, num_heads)\n",
        "    # Convert HeteroData counts to dict\n",
        "    counts = {ntype: data[ntype].num_nodes for ntype in data.node_types}\n",
        "    model.init_embeddings(counts, hidden_dim)\n",
        "    model.setup_layers(data.metadata(), text_dim, hidden_dim, num_heads)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6aeef9c7",
      "metadata": {
        "id": "6aeef9c7"
      },
      "source": [
        "## 5. Evaluation & Training Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9732e328",
      "metadata": {
        "id": "9732e328"
      },
      "outputs": [],
      "source": [
        "def align_text_embeddings(movie_map, pt_file_path):\n",
        "    data = torch.load(pt_file_path, weights_only=False)\n",
        "    raw_ids, ov_embs, rev_embs, masks = data['movie_ids'], data['overview_embs'], data['review_embs'], data['review_mask']\n",
        "\n",
        "    num_movies = len(movie_map)\n",
        "    dim = ov_embs.shape[1]\n",
        "    max_rev = rev_embs.shape[1]\n",
        "\n",
        "    ao = torch.zeros((num_movies, dim))\n",
        "    ar = torch.zeros((num_movies, max_rev, dim))\n",
        "    am = torch.zeros((num_movies, max_rev))\n",
        "\n",
        "    for i, mid in enumerate(raw_ids):\n",
        "        if mid in movie_map:\n",
        "            idx = movie_map[mid]\n",
        "            ao[idx] = ov_embs[i]\n",
        "            ar[idx] = rev_embs[i]\n",
        "            am[idx] = masks[i]\n",
        "    return ao, ar, am\n",
        "\n",
        "class BPRDataset(Dataset):\n",
        "    def __init__(self, train_df, user_map, movie_map):\n",
        "        self.data = []\n",
        "        valid_u = set(user_map.keys())\n",
        "        valid_m = set(movie_map.keys())\n",
        "        self.user_hist = defaultdict(set)\n",
        "        self.all_items = list(movie_map.values())\n",
        "\n",
        "        pos_df = train_df[train_df['rating'] >= 4]\n",
        "\n",
        "        for u, m in zip(pos_df['user_id'], pos_df['movie_id']):\n",
        "            if u in valid_u and m in valid_m:\n",
        "                uid, mid = user_map[u], movie_map[m]\n",
        "                self.data.append((uid, mid))\n",
        "                self.user_hist[uid].add(mid)\n",
        "\n",
        "    def __len__(self): return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        u, pos = self.data[idx]\n",
        "        while True:\n",
        "            neg = np.random.choice(self.all_items)\n",
        "            if neg not in self.user_hist[u]: break\n",
        "        return torch.tensor(u), torch.tensor(pos), torch.tensor(neg)\n",
        "\n",
        "def prepare_eval_data(train_df, test_df, movies_df, mappings):\n",
        "    print(\"Constructing Evaluation Dictionaries...\")\n",
        "    ground_truth = (test_df[test_df['rating'] >= 4]\n",
        "                    .groupby('user_id')\n",
        "                    .apply(lambda x: dict(zip(x['movie_id'].astype(str), x['rating'])))\n",
        "                    .to_dict())\n",
        "    ground_truth = {str(k): v for k, v in ground_truth.items()}\n",
        "\n",
        "    item_popularity = train_df.groupby('movie_id')['rating'].count().to_dict()\n",
        "    item_popularity = {str(k): v for k, v in item_popularity.items()}\n",
        "\n",
        "    item_features = mappings['movie_genres']\n",
        "    all_items = set(str(m) for m in mappings['movie_map'].keys())\n",
        "    return ground_truth, item_popularity, item_features, all_items\n",
        "\n",
        "def generate_recommendations(model, data, mappings, ov, rev, mask, train_df, k=50):\n",
        "    print(\"Generating Recommendations...\")\n",
        "    model.eval()\n",
        "\n",
        "    # Prepare Graph Inputs\n",
        "    x_dict = {n: torch.arange(data[n].num_nodes).to(device) for n in data.node_types}\n",
        "    edge_index_dict = {e: data[e].edge_index for e in data.edge_types}\n",
        "    edge_attr_dict = {}\n",
        "    for e in data.edge_types:\n",
        "        if 'rating' in data[e]:\n",
        "            edge_attr_dict[e] = data[e].rating\n",
        "\n",
        "    u_all, i_all = model.get_all_embeddings(x_dict, edge_index_dict, edge_attr_dict, ov, rev, mask)\n",
        "\n",
        "    user_history = train_df.groupby('user_id')['movie_id'].apply(set).to_dict()\n",
        "    test_users = list(mappings['id_to_user'].keys())\n",
        "    id_to_movie = mappings['id_to_movie']\n",
        "\n",
        "    recommendations = {}\n",
        "    BATCH = 100\n",
        "    num_items = i_all.shape[0]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(0, len(test_users), BATCH)):\n",
        "            batch_idx = test_users[i : i + BATCH]\n",
        "            u_emb = u_all[batch_idx]\n",
        "\n",
        "            x = torch.cat([\n",
        "                u_emb.unsqueeze(1).expand(-1, num_items, -1),\n",
        "                i_all.unsqueeze(0).expand(len(batch_idx), -1, -1)\n",
        "            ], dim=-1)\n",
        "\n",
        "            scores = model.predict_layer(x).squeeze(-1)\n",
        "            _, top_indices = torch.sort(scores, descending=True)\n",
        "            top_indices = top_indices.cpu().numpy()\n",
        "\n",
        "            for j, u_pyg_id in enumerate(batch_idx):\n",
        "                real_u_id = str(mappings['id_to_user'][u_pyg_id])\n",
        "                seen = user_history.get(int(real_u_id), set())\n",
        "                recs = []\n",
        "                for item_idx in top_indices[j]:\n",
        "                    real_item = id_to_movie[item_idx]\n",
        "                    if real_item not in seen:\n",
        "                        recs.append(str(real_item))\n",
        "                        if len(recs) == k: break\n",
        "                recommendations[real_u_id] = recs\n",
        "    return recommendations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "322fda8d",
      "metadata": {
        "id": "322fda8d"
      },
      "source": [
        "## 6. Execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e822cd94",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "e822cd94",
        "outputId": "1b037889-a9b8-4746-906d-b684a3f8520a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading datasets...\n",
            "Building User-Movie edges with Ratings...\n",
            "Model Params: 5965826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 86/86 [00:22<00:00,  3.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.3642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 86/86 [00:21<00:00,  3.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.3102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 86/86 [00:24<00:00,  3.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.3088\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 86/86 [00:22<00:00,  3.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.3052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 86/86 [00:22<00:00,  3.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.2988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 86/86 [00:22<00:00,  3.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.2971\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 86/86 [00:23<00:00,  3.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.2947\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|██████████| 86/86 [00:22<00:00,  3.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.2922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|██████████| 86/86 [00:22<00:00,  3.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.2807\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|██████████| 86/86 [00:22<00:00,  3.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.2718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11: 100%|██████████| 86/86 [00:22<00:00,  3.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.2634\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12: 100%|██████████| 86/86 [00:22<00:00,  3.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.2558\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13: 100%|██████████| 86/86 [00:22<00:00,  3.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.2528\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14: 100%|██████████| 86/86 [00:22<00:00,  3.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.2568\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15: 100%|██████████| 86/86 [00:22<00:00,  3.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.2488\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Load Data (PyG)\n",
        "data, mappings, train_df, test_df = load_data_and_build_graph()\n",
        "data = data.to(device)\n",
        "\n",
        "# Text\n",
        "ov, rev, mask = align_text_embeddings(mappings['movie_map'], TEXT_EMBED_PATH)\n",
        "ov, rev, mask = ov.to(device), rev.to(device), mask.to(device)\n",
        "\n",
        "# Dataset\n",
        "dataset = BPRDataset(train_df, mappings['user_map'], mappings['movie_map'])\n",
        "loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# Model\n",
        "model = create_model(data, 384, HIDDEN_DIM, ATTENTION_HEADS).to(device)\n",
        "opt = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "print(f\"Model Params: {sum(p.numel() for p in model.parameters())}\")\n",
        "\n",
        "# Train\n",
        "loss_hist = []\n",
        "\n",
        "# Pre-fetch graph inputs to avoid dictionary overhead in loop\n",
        "x_dict = {n: torch.arange(data[n].num_nodes).to(device) for n in data.node_types}\n",
        "edge_index_dict = {e: data[e].edge_index for e in data.edge_types}\n",
        "edge_attr_dict = {}\n",
        "for e in data.edge_types:\n",
        "    if 'rating' in data[e]:\n",
        "        edge_attr_dict[e] = data[e].rating\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    ep_loss = 0\n",
        "    for u, pos, neg in tqdm(loader, desc=f\"Epoch {epoch+1}\"):\n",
        "        u, pos, neg = u.to(device), pos.to(device), neg.to(device)\n",
        "\n",
        "        p_ov, p_rev, p_mask = ov[pos], rev[pos], mask[pos]\n",
        "        n_ov, n_rev, n_mask = ov[neg], rev[neg], mask[neg]\n",
        "\n",
        "        # Forward Pass Positive\n",
        "        pos_sc = model(x_dict, edge_index_dict, edge_attr_dict, u, pos, p_ov, p_rev, p_mask)\n",
        "        # Forward Pass Negative\n",
        "        neg_sc = model(x_dict, edge_index_dict, edge_attr_dict, u, neg, n_ov, n_rev, n_mask)\n",
        "\n",
        "        loss = -torch.mean(torch.log(torch.sigmoid(pos_sc - neg_sc)))\n",
        "\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        ep_loss += loss.item()\n",
        "\n",
        "    avg = ep_loss / len(loader)\n",
        "    loss_hist.append(avg)\n",
        "    print(f\"Loss: {avg:.4f}\")\n",
        "\n",
        "plt.plot(loss_hist)\n",
        "plt.title(\"BPR Loss (PyG)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31dd12ba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31dd12ba",
        "outputId": "d95d031c-701b-4b50-b2c4-e22f68e596f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating Recommendations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 50.32it/s]\n",
            "/tmp/ipython-input-4134193410.py:50: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda x: dict(zip(x['movie_id'].astype(str), x['rating'])))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Constructing Evaluation Dictionaries...\n",
            "Generated Recs for 943 users.\n",
            "\n",
            "============================================================\n",
            "RECOMMENDATION EVALUATION RESULTS\n",
            "============================================================\n",
            "\n",
            "CATALOG COVERAGE:\n",
            "  @10: 0.0849\n",
            "  @20: 0.1282\n",
            "  @50: 0.2350\n",
            "\n",
            "F1:\n",
            "  @10: 0.1823\n",
            "  @20: 0.2020\n",
            "  @50: 0.2052\n",
            "\n",
            "INTRA LIST SIMILARITY:\n",
            "  @10: 1.0000\n",
            "  @20: 1.0000\n",
            "  @50: 1.0000\n",
            "\n",
            "MAP:\n",
            "  @10: 0.4793\n",
            "  @20: 0.4241\n",
            "  @50: 0.3450\n",
            "\n",
            "MRR:\n",
            "  @10: 0.5456\n",
            "  @20: 0.5509\n",
            "  @50: 0.5528\n",
            "\n",
            "NDCG:\n",
            "  @10: 0.3189\n",
            "  @20: 0.3153\n",
            "  @50: 0.3451\n",
            "\n",
            "NOVELTY:\n",
            "  @10: 8.1065\n",
            "  @20: 8.3260\n",
            "  @50: 8.6478\n",
            "\n",
            "PRECISION:\n",
            "  @10: 0.2682\n",
            "  @20: 0.2259\n",
            "  @50: 0.1673\n",
            "\n",
            "RECALL:\n",
            "  @10: 0.1476\n",
            "  @20: 0.2383\n",
            "  @50: 0.4086\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "recs = generate_recommendations(model, data, mappings, ov, rev, mask, train_df)\n",
        "gt, pop, feats, all_items = prepare_eval_data(train_df, test_df, pd.read_csv('movies_graph_ready.csv'), mappings)\n",
        "\n",
        "print(f\"Generated Recs for {len(recs)} users.\")\n",
        "results = evaluate_recommendations(recs, gt, [10, 20, 50], pop, feats, all_items)\n",
        "print_evaluation_results(results)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.1"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}